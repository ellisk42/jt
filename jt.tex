\documentclass{beamer}
\usepackage{tipa}
\usepackage{phonrule}
%\setbeamersize{text margin left=10pt,text margin right=10pt}
\usetheme[numbering=none]{metropolis}
\usepackage{media9}
\usepackage{listings}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{verbatim}
\usepackage{phonrule}
%\usepackage{tipa}
\usepackage{tikz}
\usetikzlibrary{fit}
\usepackage{color}
\usepackage{booktabs}
\usepackage{tipa}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage[absolute,overlay]{textpos}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{decorations.pathmorphing}
\tikzset{squiggle/.style={decorate, decoration={snake,amplitude=.4mm}}}
\usepackage{xcolor}
\definecolor{pop1}{HTML}{1F78b4}
\definecolor{pop2}{HTML}{164C13}
\definecolor{pop3}{HTML}{d95F02}
\definecolor{orange}{HTML}{d95F02}
\definecolor{teal}{HTML}{1b9e77}
\newcommand{\pop}[1]{\textcolor{pop1}{#1}}
\newcommand{\popp}[1]{\textcolor{pop2}{#1}}
\newcommand{\tree}[1]{\textcolor{pop3}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}
\newcommand{\teal}[1]{\textcolor{teal}{#1}}
\newcommand{\code}[1]{{\footnotesize\texttt{#1}}}
\newcommand{\greenCode}[1]{{\footnotesize\popp{\code{#1}}}}
\newcommand{\blueCode}[1]{{\footnotesize\pop{\code{#1}}}}
\definecolor{backgroundGreen}{HTML}{23373b}
\lstset{escapeinside={<@}{@>}}
\usepackage{pgf}  

%% \usepackage[sfdefault]{FiraSans} %% option 'sfdefault' activates Fira Sans as the default text font
%% \usepackage[T1]{fontenc}
%% \renewcommand*\oldstylenums[1]{{\firaoldstyle #1}}

\newcommand{\closex}[2]{
  \renewcommand{\arraystretch}{#1}
  #2
  \renewcommand{\arraystretch}{1}
}
\newcommand{\closey}[2]{
  \setlength{\tabcolsep}{#1}
  #2
  \setlength{\tabcolsep}{6pt}
}

\newcommand{\person}[2]{\closex{0.2}{\begin{tabular}{c}
    {\footnotesize #1}\\
    \includegraphics[width = 1.7cm]{#2}
\end{tabular}}}
\newcommand{\bigPerson}[2]{\closex{0.2}{\begin{tabular}{c}
    {#1}\\
    \includegraphics[width = 3cm]{#2}
\end{tabular}}}


\newcommand{\Expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\indicator}{\mathds{1}} %{{\rm I\kern-.3em E}}
\newcommand{\expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\probability}{\mathds{P}} %{{\rm I\kern-.3em P}}
\DeclareMathOperator*{\argmin}{arg\,min} % thin space, limits underneath in displays
\DeclareMathOperator*{\argmax}{arg\,max} % thin space, limits underneath in displays

\usepackage[absolute,overlay]{textpos}

\newcommand{\nextForm}[1]{\rotatebox[origin=c]{270}{$_{\curvearrowright}$}$_{#1}$}
 
\usepackage{amsfonts}
\usepackage{tabularx}
%\usepackage{color}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{trees}
\usetikzlibrary{fit}
\usetikzlibrary{calc}
\usetikzlibrary{bayesnet}
\usepackage[absolute,overlay]{textpos}
\usepackage{stmaryrd}
\newcommand{\sem}[1]{\llbracket #1\rrbracket}
\newcommand{\tuple}[1]{\ensuremath{\left \langle #1\right \rangle}}
\newcommand{\messageOverlay}[1]{
      \tikz[overlay,remember picture]
      \node[align=left,fill=backgroundGreen,text=white] at (current page.center){#1};
}
\newcommand{\myPaper}[1]{
  \tikz[overlay,remember picture]
  \node[anchor=south west,align=left] at (current page.south west){#1};
}
\newcommand{\myPaperRight}[1]{
  \tikz[overlay,remember picture]
  \node[anchor=south east,align=left] at (current page.south east){#1};
}
\usepackage{booktabs}
\usepackage{tipa}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage[absolute,overlay]{textpos}
\usepackage{pifont}% http://ctan.org/pkg/pifont
%% \newcommand{\cmark}{\ding{51}}%
%% \newcommand{\xmark}{\ding{55}}%
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations.markings}

\newcommand\Wider[2][3em]{%
\makebox[\linewidth][c]{%
  \begin{minipage}{\dimexpr\textwidth+#1\relax}
  \raggedright#2
  \end{minipage}%
  }%
}
\definecolor{backgroundBeige}{RGB}{250,250,250}
\newcommand{\denotation}[1]{{\llbracket #1 \rrbracket}}

\usepackage[utf8]{inputenc}
\newcommand{\reduce}{\longrightarrow}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont

\usepackage{fancyvrb}

\usepackage[most]{tcolorbox}
\definecolor{block-gray}{gray}{0.10}
\newtcolorbox{mycode}{colback=block-gray,grow to right by=0mm,grow to left
by=0mm, boxrule=0pt,boxsep=0pt,breakable,fontupper=\color{white}}

%% Program ::=
%%   (if Bool List
%%     (append RecursiveList
%%             RecursiveList
%%             RecursiveList))
%% RecursiveList ::= List
%%          | (recurse List)

            

\usepackage{arydshln}

%\newcommand{\Expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\Probability}{\mathds{P}} %{{\rm I\kern-.3em P}}
%\usepackage{cancel}
%\DeclareMathOperator*{\argmax}{arg\,max}
%Information to be included in the title page:
%\usepackage{soul}
\usepackage[normalem]{ulem}
\title{Building Machines that Discover Generalizable, Interpretable Knowledge}
\author{Kevin Ellis}
\institute{Cornell University} 
\date{2022}
  
 
\begin{document}
 
\frame{\titlepage}

\begin{frame}{What computational problems are solved by intelligence?}
  \Wider[5em]{
    \centering\textbf{an endless range of problems}

    \begin{tabular}{ccc}
      language&science&design\\%&engineering\\
      \includegraphics[height = 2cm]{figures/acquisition}&
      \includegraphics[height = 2cm]{figures/blackboard}&
      \includegraphics[height = 2cm]{figures/textile2}\\
%      \includegraphics[height = 2cm]{figures/primitiveTools}\\
      using new devices&writing new characters&coding\\
      \includegraphics[height = 2cm]{figures/noodles}&
      \includegraphics[height = 2cm]{figures/Korean}&
      \includegraphics[height = 2cm]{../ecPaper/figures/1975.png}\\
      \multicolumn{2}{c}{engineering}&play\\
      \includegraphics[height = 2cm]{figures/igloo}&
      \includegraphics[height = 2cm]{../ecPaper/figures/aqueduct}&
      \includegraphics[height = 2cm]{figures/childPlaying}
    \end{tabular}
  }
  %% \pause
  %% \messageOverlay{- learning from modest data/experience\\
  %%   - communicating \& representing knowledge in understandable formats\\
  %%   - bootstrapping \& learning-to-learn\\
  %%   - creatively composing knowledge to produce new concepts and artifacts\\
  %%   \phantom{test}(\& compositionality)
  %% }
\end{frame}

\begin{frame}{What computational frameworks can \\contribute to this picture?}

  \Wider[5em]{\begin{center}
      \begin{tabular}{ccc}
        \multicolumn{3}{c}{Three AI traditions}\\
        \visible<2->{Symbolic}&\visible<3->{Probabilistic}&\visible<4->{Neural}\\\\
        \visible<2->{\begin{tabular}{c}
            \includegraphics[width = 3cm]{figures/deepBlue}\\%Chess\\
            \includegraphics[width = 3cm]{figures/Mathematica}\\%Mathematica\\
%            \includegraphics[width = 3cm]{figures/Lispsymbolic}\\Lisp
        \end{tabular}}&
        \visible<3->{\begin{tabular}{c}
            \includegraphics[width = 3cm]{figures/bayesianNetwork}\\
%            \includegraphics[width = 3cm]{figures/voice}\\Voice recognition\\
           \includegraphics[width = 3cm]{figures/seismic} %\\Nuclear test monitoring
        \end{tabular}}&
        \visible<4->{\begin{tabular}{c}
          \includegraphics[width = 3cm]{figures/dqn2}\\
          \includegraphics[width = 3cm]{figures/Alex2} %\\Image recognition\\
          
        \end{tabular}}
      \end{tabular}
  \end{center}}
  
  

  \visible<5->{
    \messageOverlay{\textbf{Program induction}\\ %% roots in the works of Solomonoff, Fodor, McCarthy.
    machines that learn, perceive, and reason,\\\phantom{test} by writing their own code
    }
  }

    %% strong generalization

    %% data efficiency

    %% interpretability

    %% compositional reuse

    %% universal Turing-computable expressiveness
    %Combines and complements these three traditions
%  }

  %% \pause

  %% \messageOverlay{my work:\\%% \\\phantom{test} how program induction can contribute to the engineering of machine intelligence\\
  %%   %% in engineering terms:\\
  %%   \phantom{test} how learning can make program synthesis more scalable \& practical\\
  %%   \phantom{test} how program synthesis can contribute to machine intelligence
  %%  } 
  
  

\end{frame}

\begin{frame}{Why program induction?}
  \Wider[6.5em]{  \begin{tabular}{ccc}
    \visible<2->{\begin{tabular}{l}
      strong generalization\\
      +data efficiency
    \end{tabular}}&
    \visible<3->{\begin{tabular}{l}
      interpretability\\
    \end{tabular}}
    &\visible<4->{\begin{tabular}{l}
       universal expressivity\\
     \end{tabular}}\\
    \visible<2->{
      \begin{tabular}{c}
        \includegraphics[width = 3cm]{figures/polynomialExtrapolation}\\
        {\small\texttt{f(x)=(x-1)**2 - 0.5}}
    \end{tabular}}&
    \visible<3->{\begin{tabular}{c}
        \includegraphics[width = 3.5cm]{figures/explodedCAD}\\\emph{vs}\\
        \includegraphics[width = 3.5cm]{figures/drillMesh}
    \end{tabular}}&
    \visible<4->{%% \includegraphics[width = 4cm]{figures/turingMachine}
      \begin{tabular}{c}
        \includegraphics[width = 3cm]{figures/famous}
    \end{tabular}}
  \end{tabular}}
\end{frame}


\begin{frame}{Human program induction}
 %\begin{tikzpicture} \node () {
     \includegraphics[width = 11cm]{../ecPaper/theory.png}
 %  }; \node at (-5,-4) {  }; \end{tikzpicture}
 \myPaper{Ullman et al 2012}
\end{frame}

\begin{frame}{Human program induction}
  \begin{tikzpicture}
    \node at(0,0) {\includegraphics[width = 8cm]{../ecPaper/characters.png}};
    \node at(-3,2) {\includegraphics[width = 8cm]{../ecPaper/Brendan.jpg}};

    \node at (-5,-4) {  Lake et al 2015};
    \end{tikzpicture}
\end{frame}


\begin{frame}{Can we engineer program induction systems?}

  better toolkits: neural+probabilistic+symbolic, and knowing how to combine them % we now know how to use all these things together

  \pause

  \phantom{better toolkits: }maturing \textbf{program synthesis} techniques

  \vspace{0.5cm}


  \pause

  better compute+parallel algorithms
%  \\

  
  %% \begin{itemize}
  %% \visible<2->{\item \textbf{probabilistic} methods for uncertainty and learning-to-learn}
  %% \visible<3->{\item \textbf{neural} methods for guiding combinatorial search}
  %% \visible<4->{\item \textbf{symbolic} methods, from the \textbf{programming languages} community
  %%   \begin{itemize}
  %%   \item maturing \textbf{program synthesis} techniques
  %%   \item type systems, program analysis, constraint solving, ...
  %%   \end{itemize}   }
  %% \end{itemize}


\end{frame}


\begin{frame}[fragile]{Perception, Synthesizing models, Learning-to-Learn}

  Theme \#1: high-level visual understanding, pixels$\to $programs %going from high-dimensional percepts to symbolic program representations

  \centering
  
  \includegraphics[width = \textwidth]{graphicsTeaser.pdf}
\end{frame}
\begin{frame}[fragile]{Perception, Synthesizing models, Learning-to-Learn}

  Theme \#1: high-level visual understanding, pixels$\to $programs %going from high-dimensional percepts to symbolic program representations  
Theme \#2: synthesizing human-understandable models

\begin{center}
  \includegraphics[width = 0.6\textwidth]{phonology/qualitativeSupplement2.pdf}
\end{center}
\end{frame}

\begin{frame}[fragile]{Perception, Synthesizing models, Learning-to-Learn}
  Theme \#1: high-level visual understanding, pixels$\to $programs\\ %going from high-dimensional percepts to symbolic program representations  
  Theme \#2: Synthesizing human-understandable models\\
  Theme \#3: learning to synthesize programs\\

  \vspace{0.5cm}\\

  
  \Wider[3em]{
    \includegraphics[width = \textwidth]{figures/manyDomains.png}
    }
\end{frame}

\begin{frame}{}
  \begin{center}
    \begin{tabular}{l}
      {\textcolor{black}{Program Induction and perception}}\\
      \phantom{Program Induction and }{\textcolor{gray}{model discovery}}\\
      \phantom{Program Induction and }{\textcolor{gray}{learning to learn}}
      \end{tabular}
  \end{center}
\end{frame}

\begin{frame}{Vision is more than knowing what is where}

  Can you visually extrapolate this aqueduct?

  \only<1>{
    \includegraphics[width = 0.99\textwidth]{figures/aqueductCovered}
  }
  \only<2>{
    \includegraphics[width = 0.99\textwidth]{figures/aqueduct}
  }

\end{frame}

\begin{frame}{Vision is more than knowing what is where}

  Can you infer what goes in the ellipses?

  \vspace{1cm}

  \begin{center}
    \includegraphics[width = \textwidth]{figures/RNN-unrolled}
  \end{center}
\end{frame}

\begin{frame}{Vision is more than knowing what is where}
  \includegraphics[width = \textwidth]{figures/CAD_laptop}
\end{frame}

\begin{frame}[fragile]{Learning to infer graphics programs from hand-drawn images}
  \begin{center}
    \begin{tikzpicture}
      \node[draw,label={hand drawing}](picture1) at (0,-1) {\includegraphics[height = 2.2cm]{TikZfigures/expert-31-trim.png}};
      \node[label={%% [align=right]left:
          machine-generated program},draw,right=1cm of picture1] (c1) {
        \begin{lstlisting}[basicstyle = \small\ttfamily]
for (0 <= i < 3)
 rectangle(3*i,-2*i+4,
           3*i+2,6)
 for (0 <= j < i + 1)
  circle(3*i+1,-2*j+5)
        \end{lstlisting}
      };
      
      \draw[very thick,->] (picture1.east)  -- (c1.west);

      %    \node(l1)[anchor=south] at ([yshift=0.75cm,xshift=2.5cm]picture1.north) {model infers program from drawing};
    \end{tikzpicture}

  \end{center}
%    \vskip0pt plus 1filll
  \myPaper{Ellis, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.}
  \begin{tikzpicture}[remember picture, overlay,label distance=-2mm] \node[anchor=south east, label={Dan Ritchie}] at (current page.south east) {\includegraphics[width = 2cm]{collaborators/Daniel}}; \end{tikzpicture}
\end{frame}

\begin{frame}[fragile]{Learning to infer graphics programs from hand-drawn images}
  \begin{center}
    \begin{tikzpicture}
      \node[draw,label={hand drawing}](picture1) at (0,-1) {\includegraphics[height = 2.2cm]{TikZfigures/expert-31-trim.png}};
      \node[label={%% [align=right]left:
          machine-generated program},draw,right=1cm of picture1] (c1) {
        \begin{lstlisting}[basicstyle = \small\ttfamily]
for (0 <= i < 3 <@\textcolor{red}{\textbf{+ 1}}@>)
 rectangle(3*i,-2*i+4,
           3*i+2,6)
 for (0 <= j < i + 1)
  circle(3*i+1,-2*j+5)
        \end{lstlisting}
      };
      
      \draw[very thick,->] (picture1.east)  -- (c1.west);

      %    \node(l1)[anchor=south] at ([yshift=0.75cm,xshift=2.5cm]picture1.north) {model infers program from drawing};
    \end{tikzpicture}

  \end{center}
%    \vskip0pt plus 1filll
    \myPaper{Ellis, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.}
\end{frame}

\begin{frame}[fragile]{Learning to infer graphics programs from hand-drawn images}
\hspace*{-0.45cm}\begin{tikzpicture}
      \node[draw,label={hand drawing}](picture1) at (0,-1) {\includegraphics[height = 2.2cm]{TikZfigures/expert-31-trim.png}};
      \node[label={%% [align=right]left:
          machine-generated program},draw,right=1cm of picture1] (c1) {
        \begin{lstlisting}[basicstyle = \small\ttfamily]
for (0 <= i < 3 <@\textcolor{red}{\textbf{+ 1}}@>)
 rectangle(3*i,-2*i+4,
           3*i+2,6)
 for (0 <= j < i + 1)
  circle(3*i+1,-2*j+5)
        \end{lstlisting}
      };
      
      \draw[very thick,->] (picture1.east)  -- (c1.west);
\end{tikzpicture}


\myPaper{Ellis, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.}

\end{frame}




\begin{frame}[fragile]{Learning to infer graphics programs from hand-drawn images}
\hspace*{-0.9cm}\begin{tikzpicture}
        \node[draw,label={[align=center]hand drawing}](picture1) at (0,-1) {\includegraphics[height = 2.2cm]{TikZfigures/expert-31-trim.png}};

     \node[label={machine-generated program},draw,right=1cm of picture1] (c1) {
        \begin{lstlisting}[basicstyle = \small\ttfamily]
for (0 <= i < 3 <@\textcolor{red}{\textbf{+ 1}}@>)
 rectangle(3*i,-2*i+4,
           3*i+2,6)
 for (0 <= j < i + 1)
  circle(3*i+1,-2*j+5)
\end{lstlisting}
     };
      
      \draw[very thick,->] (picture1.east)  -- (c1.west);    

      \node(e)[anchor=west,label={[align=center]autogenerated\\extrapolation}] at ([xshift=1cm]c1.east) {\includegraphics[width = 2.2cm]{TikZfigures/31-extrapolated-trim.png}};
      
      \draw[very thick,->] (c1.east)  -- (e.west);
      \node[anchor=south west] at ([yshift=-1cm]picture1.south west) {\textbf{one-shot generalization / extrapolation}};
    \end{tikzpicture}


  \myPaper{Ellis, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.}  
\end{frame}

\begin{frame}{Extrapolation from a single image}
  \Wider[5em]{
    \includegraphics[width = \textwidth]{TikZfigures/extrapolationMatrix1improved.png}
  }
  \myPaper{Ellis, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.}  
\end{frame}

\begin{frame}[fragile]{How to infer graphics programs from hand-drawn images}

\hspace*{-1cm}\begin{tikzpicture}[scale=0.9]
  \node[ thick,anchor = west,inner sep=0pt,label={[yshift = 0.3cm]{\small \begin{tabular}{c}
          \textbf{Image}\\
          \textbf{(Observed)}
  \end{tabular}}}](observation) at (0,0) {\includegraphics[width = 1.5cm]{TikZfigures/expert-39-trimmed.png}};
    \node[ultra thick,anchor = west,inner sep=0pt](traceSource) at (3.7,0.5){    \begin{lstlisting}[basicstyle = \scriptsize\ttfamily]
line, line,
rectangle,
line, ...
\end{lstlisting}};
    \node[ultra thick,anchor = west,inner sep=0pt](traceImage) at (4.15,-0.6) {
      \includegraphics[width = 0.9cm]{TikZfigures/39-parse.png}}; 
    \node(trace)[draw,thick,fit = (traceImage) (traceSource), label = above:{{\small \begin{tabular}{c}
            \textbf{Drawing Commands}\\
            \textbf{(Latent)}
    \end{tabular}}}] {};
    
    \node[draw, thick,anchor = west,inner sep=2pt,label=above:{\small \begin{tabular}{c}
          \textbf{Program}\\
          \textbf{(Latent)}
    \end{tabular}}](program) at (7.7,0) {
      \begin{lstlisting}[basicstyle = \scriptsize\ttfamily]
for (j < 3)
for (i < 3)
if (...)
 line(...)
 line(...)
rectangle(...)
    \end{lstlisting}};

%    \node[ultra thick,anchor = west,inner sep=0pt,label=below:{\small Similarity}](similarity) at (11.3,0) {\includegraphics[width = 1cm]{TikZfigures/expert-38-trim.png}};


    
    \draw[->, ultra thick] ([yshift=10]trace.west) to[out = 150,in = 30] node[midway,yshift = 6]{{\small render}} ([xshift=5,yshift=10]observation.east); % -- node[fill = white,rotate = -90] {{\small Rendering}}
    \draw[->, ultra thick] ([yshift=10]program.west) to[out = 150,in = 30] node[midway,yshift = 6] {{\small exec}} ([yshift=10]trace.east);
    
    \pause
    \draw[->, very thick, red] ([yshift = -15,xshift=3]observation.east) to[out = -30,in = -150] node[midway,yshift = -35,xshift=0]{{\small \begin{tabular}{l}
          neural network+ \\sequential monte carlo
    \end{tabular}}} ([yshift = -15]trace.west);

    \draw[->, very thick, red] ([yshift = -15,xshift=0]trace.east) to[out = -30,in = -150] node[midway,yshift = -35,xshift=53]{{\small \begin{tabular}{l}
          learning+ \\constraint-based program synthesis
    \end{tabular}}} ([yshift = -15]program.west);
%    \draw[->, thick, red, very thick] ([xshift = 10]trace.south) to[out = -10,in = -170] node[midway,yshift = -6]{{\small Learning + Program synthesis}} ([xshift = 10]program.south);
%    \draw[->, thick, red] (program.east) to[out = 80,in = 180] (errors.west);
%    \draw[->, thick] (program.east) to[out = 40,in = -230] (similarity.west);


    \draw[decoration = {brace,mirror,raise = 5pt},decorate,thick]
    ([yshift = -40,xshift = -130]trace.south) -- node[below = 6pt] {{\small  Image$\to$Parse}} ([yshift = -40,xshift = -5]trace.south);
    \draw[decoration = {brace,mirror,raise = 5pt},decorate,thick]
    ([xshift = 5,yshift = -40]trace.south) -- node[below = 6pt] {{\small Parse$\to$Program}} ([xshift = 170,yshift = -40]trace.south);

    \pause
    \node[ultra thick,anchor = west,inner sep=0pt,label=below:{\small extrapolation}](extrapolate) at (11.8,0.9) {\includegraphics[width = 1.3cm]{TikZfigures/39-extrapolated.png}};
    \draw[->, thick, red, very thick] (program.east) to[out = 60,in = 180] (extrapolate.west);
    \node[ultra thick,anchor = west,text width = 2.3cm,inner sep=0pt](errors) at (11.1,-1) {\small error correction};
    
%%     \draw[decoration = {brace,mirror,raise = 5pt},decorate,thick]
%% ([xshift = 180,yshift = -40]trace.south) -- node[below = 6pt] {{\small Applications}} ([xshift = 255,yshift = -40]trace.south);
\end{tikzpicture}

  \myPaper{Ellis, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.}  
\end{frame}

%% \begin{frame}{Parsing images into specs (\LaTeX~TikZ commands)}

%% {\footnotesize  Neurally Guided Procedural Modeling (Ritchie et al 2016) + \\Attend, Infer, Repeat (Eslami et al 2016)}
%%   \vspace{-0.5cm}
%%   \begin{center}
%%     \begin{tabular}{c}
%% \raisebox{-.5\height}{    \includegraphics[width = 0.8\textwidth]{../TikZpaper/architecture.pdf}            }
%%       \end{tabular}

%%   \end{center}

%%     \newcommand{\noisySize}{0.12\textwidth}
%%     \visible<2->{
%% \hspace{0.1\textwidth}      \begin{minipage}[t]{\noisySize}
%%         \centering\includegraphics[width = \textwidth]{TikZfigures/expert-60-reduced.png}\\
%%                                   {\small     hand drawing}
%%       \end{minipage}\hspace{0.05\textwidth}%
%%       \begin{minipage}[t]{\noisySize}
%%         \centering\includegraphics[width = \textwidth]{TikZfigures/60-1-reduced.png}\\
%%                                   {\small noisy \\rerender}
%%       \end{minipage}}%
%%     %% \visible<3->{\begin{minipage}{0.35\textwidth}
%%     %%     \begin{flushright}
%%     %%       \textbf{Learned distance metric}\\
%%     %%       \small    Serves as likelihood surrogate
%%     %%       \begin{align*}
%%     %%         \displaystyle\qquad    -\log L_{\text{learned}}(\text{render}&(S_1)|\text{render}(S_2))\approx\\& |S_1 - S_2| + |S_2 - S_1|
%%     %%       \end{align*}
%%     %%       $S_1$: noisy render\\
%%     %%       $S_2$: nonnoisy render
%%     %%     \end{flushright}
%%     %% \end{minipage}}%
%%     \hspace{0.2\textwidth}%
%%     \only<3>{\begin{minipage}[c]{0.3\textwidth}
%% \vspace{0.4cm}      \includegraphics[width = 0.8\textwidth]{TikZfigures/evaluationPhase1}
%%     \end{minipage}}
%%         \only<4>{\begin{minipage}[c]{0.3\textwidth}
%% \vspace{0.4cm}      \includegraphics[width = 0.8\textwidth]{TikZfigures/evaluationPhase2}
%%     \end{minipage}}
%% \end{frame}

%% \begin{frame}{Learning to quickly synthesize programs}
%%     Learn search policy $\pi (\text{program subspace} | \text{spec})$
%%   \\Think of the subspace as an ``ansatz''

%% OBJECTIVE: Small subspace for tractability while also being likely to contain good programs

%% %  \vspace{0.7cm}
%% \Wider[5em]{   \begin{tikzpicture}[scale=0.7]
%%     \footnotesize
%%     \node[anchor = west] at (0,5.25) {{ Entire program search space}};
%%     %\footnotesize
%%     \draw[fill = yellow,fill opacity = 0.15,draw = black] (0,0) rectangle (5,5);
%% \pause
%% \draw [fill = yellow, opacity = 0.2] (0,0)--(0,2)--(4,0)--(0,0);
%%     \draw (0,2) -- node[below,sloped]{short progs} (4,0);
%%     \draw (0,2) -- node[above,sloped]{long progs} (4,0);
%%     \pause
    

%%     \draw [fill = yellow, opacity = 0.6] (2.5,5)--(3.2,0)--(5,0)--(5,5);
%%     \draw (2.5,5) -- node[above,sloped]{progs w/ reflections} (3.2,0);
%%     \pause
    
%%     \draw [fill = yellow, opacity = 0.4] (0,5)--(0,1)--(3,5);
%%     \draw (0,1) -- node[above,sloped]{ progs w/ loops} (3,5);
%%     \pause
    
%%     \node(p1)[anchor =west ] at (5.0,3.5) {$\pi(\text{short, no loop/reflect}|S) = $};
%%     \draw [fill = yellow, fill opacity = 0.2,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p1.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p1.east);
%%     \node(p2)[anchor =west ] at ([yshift = -0.5cm]p1.west) {$\pi(\text{long, loops}|S) = $};
%%     \draw [fill = yellow, fill opacity = 0.4,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p2.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p2.east);
%%     \node(p3)[anchor =west ] at ([yshift = -0.5cm]p2.west) {$\pi(\text{long, no loop/reflect}|S) = $};
%%     \draw [fill = yellow, fill opacity = 0.15,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p3.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p3.east);
%%     \node(p4)[anchor =west ] at ([yshift = -0.5cm]p3.west) {$\pi(\text{long, reflects}|S) = $};
%%     \draw [fill = yellow, fill opacity = 0.6,draw = black]  ([xshift = 0cm,yshift = -0.2cm]p4.east) rectangle ([xshift = 0.4cm,yshift = 0.2cm]p4.east);
%%     \node(p5)[anchor =west ] at ([yshift = -0.5cm]p4.west) {\emph{etc.}};
%%     \pause
%%     \node at (15.2,3) {\includegraphics[width = 3.6cm]{TikZfigures/2policyComparison}};
%%   \end{tikzpicture}}

%% \end{frame}

\begin{frame}{Top-down influences on perception}
  \Wider[2em]{
    \begin{tabular}{ccc}
    \small{\phantom{test}drawing\phantom{tttttttttttt}}&\visible<2->{\small{bottom-up neural net}}&\visible<4->{\small{w/ top-down program bias}}\\
    \multicolumn{3}{c}{\only<1>{\includegraphics[width = 0.9\textwidth]{TikZfigures/programSuccess16_1.png}}%
        \only<2>{\includegraphics[width = 0.9\textwidth]{TikZfigures/programSuccess16_2.png}}%
        \only<3>{\includegraphics[width = 0.9\textwidth]{TikZfigures/programSuccess16_3.png}}%
        \only<4>{\includegraphics[width = 0.9\textwidth]{TikZfigures/programSuccess16_4.png}}%
        \only<5->{\includegraphics[width = 0.9\textwidth]{TikZfigures/programSuccess16_5.png}}%
    }\\
    \multicolumn{3}{c}{\only<6>{\includegraphics[width = 0.9\textwidth]{TikZfigures/programSuccess71_statement.png}}}
    %        \multicolumn{3}{c}{\includegraphics[width = \textwidth]{TikZfigures/programSuccess97.png}}
    \end{tabular}
  }

  %% \only<6>{
  %%   \begin{tabular}{cc}
  %%     \begin{tabular}{c}
  %%       \begin{tikzpicture}
  %%       \node[obs](i) at (0,0) {img};
  %%       \node[latent](p) at ([yshift=0.8cm]i.north) {prog};
  %%       \node[latent](h) at ([yshift=0.8cm]p.north) {prior};
  %%       \draw[->] (h.south) -- (p.north);
  %%       \draw[->] (p.south) -- (i.north);
  %%       \node[obs](i) at ([xshift=0.8cm]i.east) {img};
  %%       \node[latent](p) at ([yshift=0.8cm]i.north) {prog};
  %%       \draw[->] (h.south) -- (p.north);
  %%       \draw[->] (p.south) -- (i.north);
  %%       \node[obs](i) at ([xshift=-1.8cm]i.west) {img};
  %%       \node[latent](p) at ([yshift=0.8cm]i.north) {prog};
  %%       \draw[->] (p.south) -- (i.north);
  %%       \draw[->] (h.south) -- (p.north);
  %%     \end{tikzpicture}
  %%       \end{tabular}&
  %%     \begin{tabular}{l}
  %%       $\text{predicted program} = $\\$\argmax_{\text{progs}}\probability\left[\text{img}|\text{prog} \right]\probability\left[\text{prog}|\text{prior} \right]$
  %%       \end{tabular}
  %%     \end{tabular}
  %% }
\end{frame}


\begin{frame}[t]{3D program induction}
  \Wider[5em]{
    \begin{center}
      \includegraphics[width = \textwidth]{assets/we_are_cool_4.png}
    \end{center}
  }

  \vspace{1cm}

  \centering{\closey{0pt}{\begin{tabular}{ccccc}
    \person{Max Nye}{collaborators/MaxNye}&
    \person{Evan Pu}{collaborators/Evan}&
    \person{Felix Sosa}{collaborators/Felix}&
    \person{Josh\\{\footnotesize Tenenbaum}}{collaborators/Josh}
    \person{Armando\\{\footnotesize Solar-Lezama}}{collaborators/Armando}
  \end{tabular}}}

    
\myPaper{Ellis$^*$, Nye$^*$, Pu$^*$, Sosa$^*$, Tenenbaum, Solar-Lezama. NeurIPS 2019.\\$^*$equal contribution}

\end{frame}

\begin{frame}[t]{3D program induction}
  \Wider[5em]{
    \begin{center}
      \includegraphics[width = \textwidth]{assets/we_are_cool_4.png}
    \end{center}
  }

    \vspace{1cm}
    
      Challenge: combinatorial search!\\
      Branching factor: $ > 1.3$ million per line of code, $\approx$ 20 lines of code\\
      search space size: $(1.3\text{ million})^{20}\approx 10^{122}$ programs
%\myPaper{Ellis$^*$, Nye$^*$, Pu$^*$, Sosa$^*$, Tenenbaum, Solar-Lezama. NeurIPS 2019.\\$^*$equal contribution}

\end{frame}



\begin{frame}{}
  Solution: stochastic \textbf{tree search} + learn \textbf{policy} that writes code\\ + learn \textbf{value} function that assesses execution of program so far;\\
  analogous to \textbf{AlphaGo} [Silver et al. 2016]

  \Wider[5em]{
    \only<1>{\includegraphics[width = \textwidth]{figures/capitalism3.png}}
    \only<2>{\includegraphics[width = \textwidth]{figures/capitalism2.png}}
    \only<3>{\includegraphics[width = \textwidth]{figures/capitalism1.png}}
    \only<4>{\includegraphics[width = \textwidth]{figures/capitalism.png}}
  }
%  \myPaper{\tiny Ellis$^*$, Nye$^*$, Pu$^*$, Sosa$^*$, Tenenbaum, Solar-Lezama. NeurIPS 2019.\\$^*$equal contribution}
\end{frame}

\begin{frame}{3D program induction}
  \Wider[5em]{
    \begin{center}
      
      \setlength{\tabcolsep}{0pt}
      \renewcommand{\arraystretch}{0}  
      
      %    \includegraphics[width = \textwidth]{assets/pixel_montage} \\
      % \begin{tabular}{cc}
      %   \includegraphics[width = 0.3\textwidth]{assets/2d_synthetic_montage}&
      %   \includegraphics[width = 0.6\textwidth]{assets/tool_montage}
      % \end{tabular}\\\\    


        \begin{tabular}{ccccccc}
        \rotatebox[origin=l]{90}{Input}
        &    \rotatebox[origin=l]{90}{(voxels)}$\;$&
        \includegraphics[width = 2cm]{assets/3-D/demo3/spec}&
        %    \includegraphics[width = 2cm]{assets/3-D/demo6/0000png_v.png}&
        \includegraphics[width = 2cm]{assets/3-D/demo2/spec}&
        \includegraphics[width = 2cm]{assets/3-D/demo4/012_png_v.png}&
        \includegraphics[width = 2cm]{assets/3-D/demo5/CAD_example_input}&
        \includegraphics[width = 2cm]{assets/3-D/demo1/spec}
        \\
        \rotatebox[origin=l]{90}{Rendered}&
        \rotatebox[origin=l]{90}{program}$\;$&
        \includegraphics[width = 2cm]{assets/3-D/demo3/000_SMC_value_pickle_pretty.png}$\;$&
        %    \includegraphics[width = 2cm]{assets/3-D/demo6/2}$\;$&
        \includegraphics[width = 2cm]{assets/3-D/demo2/pretty}$\;$&
        \includegraphics[width = 2cm]{assets/3-D/demo4/012_SMC_value_pickle_pretty}$\;$&
        \includegraphics[width = 2cm]{assets/3-D/demo5/CAD_example_output}$\;$&
        \includegraphics[width = 2cm]{assets/3-D/demo1/pretty}
        \end{tabular}
      \setlength{\tabcolsep}{6pt}
      \renewcommand{\arraystretch}{1}
    \end{center}
  }

  \visible<2>{\textbf{\large same architecture learns to synthesize text editing programs (FlashFill, Gulwani 2012)}}
  
%  \myPaper{Ellis$^*$, Nye$^*$, Pu$^*$, Sosa$^*$, Tenenbaum, Solar-Lezama. NeurIPS 2019.\\$^*$equal contribution}

\end{frame}



\begin{frame}{Lessons}

  The inductive bias from a programming language gives extrapolation, or strong generalization

  \vspace{1cm}
  
  Combine the best of different techniques: neural nets for perception and pattern recognition, symbols for reasoning, Bayesian methods for uncertainty

\end{frame}

\begin{frame}{}
  \begin{center}
    \begin{tabular}{l}
      {\textcolor{black}{Program Induction and }\textcolor{gray}{perception}}\\
      \phantom{Program Induction and }{\textcolor{black}{model discovery}}\\
      \phantom{Program Induction and }{\textcolor{gray}{learning to learn}}
      \end{tabular}
  \end{center}
\end{frame}


\begin{frame}[fragile]{Scientific discovery}

  \Wider[4em]{
    \includegraphics[width = 0.8\textwidth]{figures/distillingLaws}\\
                    {\small Schmidt \& Lipson: ``Distilling Free-Form Natural Laws from Experimental Data''}

                    \\\vspace{1cm}\\
                    \begin{tabular}{cc}
                      \begin{tabular}{c}
                        \includegraphics[width = 0.45\textwidth]{figures/genetics}
                        \end{tabular}&
                      %% \visible<2>{\hspace*{-0.5cm}\includegraphics[width = 0.53\textwidth]{figures/solomonScience2}}\\
                      \begin{tabular}{l}
                        {\small Lezon et al. 2006}\\{\small inferring genetic interaction networks}
                      \end{tabular}&
                      \end{tabular}
  }

\end{frame}

\begin{frame}[fragile]{Discovering human-understandable models of language}
  \begin{center}
    \begin{tikzpicture}[scale=0.75]
      \input{phonology/languageWheel50.tex}
    \end{tikzpicture}
  \end{center}
%%   \pause
%%   \messageOverlay{\large many languages, 70 diverse benchmarks\\\\
%%     \large linguists distill out higher-level knowledge: ``universal grammar''\\\\
%% \large children and linguists can learn from sparse data\\\\
  %% \large  linguists can communicate their knowledge}
  \begin{tikzpicture}[remember picture, overlay,label distance=-2mm] \node[anchor=south east, label={Tim O'Donnell}] at (current page.south east) {\includegraphics[width = 2cm]{collaborators/Timothy}}; \end{tikzpicture}
\end{frame}

\begin{frame}{Few-shot language learning experiment}
  Mandarin:

  \vspace{1cm}

  \begin{tabular}{rcc}
    & adjective & adverb\\
    ``slow'' & \textipa{man} & \textipa{manmand@}\\
    ``small'' & \textipa{xiao} & \textipa{xiaoxiaod@}\\
    ``fast'' & \textipa{kuai} & \only<2->{\textipa{kuaikuaid@}}\only<1>{???}
  \end{tabular}

  \vspace{1cm}
  
  \only<3>{stem+stem+\textipa{d@}}

  \end{frame}

\begin{frame}{Few-shot language learning experiment}
  Serbo-Croatian:
  \vspace{1cm}
  
  \begin{tabular}{rlll}
    &\multicolumn{1}{c}{masculine}&\multicolumn{1}{c}{feminine}&%% \only<5->{stem (unobserved)}
    \\
    ``rich''&\textipa{bogat}&\textipa{bogata}&%% \only<5->{bogat}
    \\
    ``mild''&\textipa{blag}&\textipa{blaga}&%% \only<5->{blag}
    \\
    ``green''&\textipa{zelen}&\only<1>{???}\only<2->{\textipa{zelena}}&%% \only<5->{zelen}
    \\
    \only<4->{``clear''}&\only<4>{???}\only<5>{\textbf{yasan}}& \only<4->{yasna}&%% \only<5->{yasn}
    \\  
  \end{tabular}

  \vspace{1cm}
  
  \only<3->{\emph{add ``a'' to stem to make feminine}}
  
  \only<5->{
    \emph{insert ``a'' between two word-final consonants}\\
    \phonb{$\varnothing$}{a}{C}{C\#}
  }

\end{frame}


%% \begin{frame}{Diverse Linguistic Phenomena}
%%   \includegraphics[width = \textwidth]{phonology/Croatian}
%% \end{frame}
%% \begin{frame}{Languages with tones}
%%   \includegraphics[width = \textwidth]{phonology/tonal}
%% \end{frame}
\begin{frame}
  \begin{center}
    \begin{tabular}{ccc}
      \includegraphics[width = 0.3\textwidth]{figures/odden}&
      \includegraphics[width = 0.3\textwidth]{figures/spe}&
      \includegraphics[width = 0.3\textwidth]{figures/roca}
    \end{tabular}
  \end{center}
\end{frame}
\begin{frame}{}
\Wider[5em]{  \includegraphics[width = \textwidth]{figures/Turkish1}}
\end{frame}
\begin{frame}{Turkic Sakha (Yakut)}
  \input{phonology/harmonyAnimation.tex}%  \includegraphics[width = \textwidth]{phonology/harmony}
  \myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
\begin{frame}{Turkic Sakha (Yakut)}
  \input{phonology/harmonyAnimation2.tex}%  \includegraphics[width = \textwidth]{phonology/harmony}
  \myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
%% \begin{frame}{Turkic Sakha (Yakut)}
%%   \input{phonology/harmonyAnimation3.tex}%  \includegraphics[width = \textwidth]{phonology/harmony}
%%   \myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
%% \end{frame}


\begin{frame}{}
  \Wider[5em]{
%    \only<1>{\includegraphics[width = \textwidth]{figures/betterMontage1}}
    %    \only<2>{\includegraphics[width = \textwidth]{figures/betterMontage2}}
    \only<1>{\includegraphics[width = \textwidth]{updated_phonology_results/0}}
    \only<2>{\includegraphics[width = \textwidth]{updated_phonology_results/2}}
  }
%  \myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
\begin{frame}[fragile]{Distilling higher-level knowledge}
  \Wider[5em]{
    \begin{center}
      \begin{tikzpicture}[scale=2]
        \input{languageHierarchy.tex}
      \end{tikzpicture}
  \end{center}}
  %\myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
\begin{frame}[fragile]{Distilling higher-level knowledge}
  \Wider[5em]{
    \begin{center}
      \begin{tikzpicture}[scale=2]
        \node[align=left] at (-2.2,0) {\textbf{dark}: we know it\\\textbf{light}: we wanna know it\\$\mathbf{A\to B}$: A makes B};
        \input{languageHierarchy2.tex}
      \end{tikzpicture}
  \end{center}}
  %\myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
\begin{frame}[fragile]{Distilling higher-level knowledge}
  \Wider[5em]{
    \begin{center}
      \begin{tikzpicture}[scale=2]
        \node[align=left] at (-2.2,0) {\textbf{dark}: we know it\\\textbf{light}: we wanna know it\\$\mathbf{A\to B}$: A makes B};
        \input{languageHierarchy3.tex}
      \end{tikzpicture}
  \end{center}}
  %\myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
\begin{frame}[fragile]{Distilling higher-level knowledge}
  \Wider[5em]{
    \begin{center}
      \begin{tikzpicture}[scale=2]
        \node[align=left] at (-2.2,0) {\textbf{dark}: we know it\\\textbf{light}: we wanna know it\\$\mathbf{A\to B}$: A makes B};
        \input{languageHierarchy4.tex}
      \end{tikzpicture}
  \end{center}}
  %\myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
\begin{frame}{}
  \Wider[5em]{
%    \only<1>{\includegraphics[width = \textwidth]{figures/betterMontage1}}
    %    \only<2>{\includegraphics[width = \textwidth]{figures/betterMontage2}}
    \only<1>{\includegraphics[width = \textwidth]{updated_phonology_results/2}}
    \only<2>{\includegraphics[width = \textwidth]{updated_phonology_results/3}}
  }
%  \myPaper{\small Ellis, Albright, Solar-Lezama, Tenenbaum, O'Donnell. 2022.}
\end{frame}
%% \begin{frame}{Distilling higher-level knowledge}
%%   \Wider[5em]{
%%     \begin{tabular}{rl}
%%       \begin{tabular}{c}
%%         Discovered\\ universal grammar \\schema
%%       \end{tabular}&
%%       \begin{tabular}{l}
%%         \multicolumn{1}{c}{\textbf{consonant/vowel distinction}}\\
%%         sounds$\gets$ [-vowel]\\
%%         sounds$\gets$ [+vowel]\\
%%         \emph{a set of sounds is commonly}\\\emph{ all consonants,}\\\emph{ or all vowels}
%%       \end{tabular}\\
%%       \begin{tabular}{c}
%%         w/o learned\\
%%         universal grammar
%%       \end{tabular}&
%%       Tibetan:\phantom{test}    \phonl{[-nasal]}{$\varnothing $}{\#}\\\\
%%       \begin{tabular}{c}
%%         w/ learned\\
%%         universal grammar
%%       \end{tabular}&
%%       \phantom{Tibetan:test} \phonb{[-vowel]}{$\varnothing $}{\# }{[-vowel]}

%% %% %    Kerewe&    \phonb{[ ]}{[ +hiTone ]}{[ +hiTone ] [ ] }{ [ ]}
%% %%   \end{tabular}&
      
%%     \end{tabular}
%% %%     \begin{tabular}{cll}
%% %%     \toprule&
%% %%   \multicolumn{1}{c}{Without learned universal grammar}&
%% %%   \multicolumn{1}{c}{With learned universal grammar}\\\midrule \\
%% %%   \begin{tabular}{l}
%% %%     \multicolumn{1}{c}{\textbf{consonant/vowel distinction}}\\
%% %%     sounds$\gets$ [-vowel]\\
%% %%     sounds$\gets$ [+vowel]\\
%% %%     \emph{a set of sounds is commonly}\\\emph{ all consonants,}\\\emph{ or all vowels}
%% %%   \end{tabular}&
%% %%   \begin{tabular}{rl}
%% %%     Tibetan&    \phonl{[-nasal]}{$\varnothing $}{\#}
%% %% %    Kerewe&    \phonb{[ ]}{[ +hiTone ]}{[ +hiTone ] [ ] }{ [ ]}
%% %%   \end{tabular}&
%% %%   \begin{tabular}{l}
%% %%     
%% %%   \end{tabular}
%% %%   \\\\\midrule   
%% %%   \begin{tabular}{l}
%% %%     \multicolumn{1}{c}{\textbf{nasal place assimilation}}\\
%% %%     $[\text{+nasal}]\to \alpha\text{place}$ / %\phonb{[+nasal]}{$\alpha$place}{\texttt{trigger}}{\phonfeat[c]{C\\$\alpha$place}}
%% %%     \underline{\phantom{aa}}\phonfeat[c]{C\\$\alpha$place}\\
%% %%     \emph{nasals (``n'', ``m'', ...) move to the place in the}\\
%% %%       \emph{ mouth where the next consonant is}
%% %%   \end{tabular}
%% %%   &
  
%% %%   \begin{tabular}{rl}    
%% %%     Bukusu&    \phonr{\textipa{\~n}}{$\alpha$place}{[$\alpha$place]}\\\\
%% %%   \end{tabular}
%% %%   &
%% %%   \begin{tabular}{l}
%% %%     \phonr{[+nasal]}{$\alpha$place}{\phonfeat[c]{C\\$\alpha$place}}\\\\
%% %%   \end{tabular}
%% %% \end{tabular}
%%   }
%% %\includegraphics[width = \textwidth]{phonology/universal}
%% \end{frame}






\begin{frame}{Lessons}

  Higher-level knowledge matters (``universal grammar''). Get the basics of the representation correct

  \vspace{1cm}

  But \emph{some} of this higher-level knowledge can be learned. You don't need millions of examples to learn it. But it's not a one-shot learning problem either

\end{frame}

\begin{frame}{}
  \begin{center}
    \begin{tabular}{l}
      {\textcolor{black}{Program Induction and }\textcolor{gray}{perception}}\\
      \phantom{Program Induction and }{\textcolor{gray}{model discovery}}\\
      \phantom{Program Induction and }{\textcolor{black}{learning to learn}}
      \end{tabular}
  \end{center}
\end{frame}



\begin{frame}{Learning to write code} %Growing domain-specific knowledge}
  
  %  \Large
  Goal: acquire domain-specific knowledge needed to induce a class of programs


  
  \vspace{0.75cm}

  \Wider[4em]{
    \begin{itemize}
    \item Library of concepts (declarative knowledge; domain specific language) \\ %; generative model over programs)
      \item      Inference strategy (procedural knowledge; synthesis algorithm)
      \end{itemize}
  }

  \only<1>{
    \vspace{1cm}
    \Wider[0em]{\closey{0.1}{\begin{tabular}{ccccc}
      \person{Cathy Wong}{collaborators/cw}&
      \person{Max Nye}{collaborators/MaxNye}&
      \person{Mathias\\{\footnotesize Sable-Meyer}}{collaborators/French2}&
      \person{Armando\\{\footnotesize Solar-Lezama}}{collaborators/Armando}&
      \person{Josh\\{\footnotesize Tenenbaum}}{collaborators/Josh}
    \end{tabular}}}
  }
  
  \vspace{0.75cm}
  
  \visible<2>{
  \begin{tikzpicture}
    \node(problem) at (0,0) {\includegraphics[width = 2cm]{figures/cubic.png}};
    \node(synthesizer)[draw,align=center] at ([xshift=3cm]problem.east) {Learned \\program inducer};
    \draw[->] (problem.east) -- (synthesizer.west);
    \node(program)[draw, align=center] at ([xshift=3cm]synthesizer.east) {program:\\$f(x) = 0.3x^3+$\\$1.1x^2-2x+0.6$};
    \draw[->] (synthesizer.east) -- (program.west);
  \end{tikzpicture}
  
    \vspace{0.2cm}Concepts: $x^3$, $\alpha x + \beta$, etc\\Inference strategy: neurosymbolic search for programs}
  %% \renewcommand\code\texttt
  %%   \only<3>{
  %% \begin{tikzpicture}
  %%   \node(problem) at (0,0) {\includegraphics[width = 2cm]{figures/radialCircle.png}};
  %%   \node(synthesizer)[draw,align=center] at ([xshift=3cm]problem.east) {Learned \\program inducer};
  %%   \draw[->] (problem.east) -- (synthesizer.west);
  %%   \node(program)[draw, align=center] at ([xshift=3cm]synthesizer.east) {program:\\\code{(radial-symmetry 5}\\\code{ (circle 3))}};
  %%   \draw[->] (synthesizer.east) -- (program.west);
  %% \end{tikzpicture}
  
  %% \vspace{0.2cm}Concepts: \code{circle}, \code{radial-symmetry}, etc\\Inference strategy: neurosymbolic search for programs
  %%   }
\end{frame}


\begin{frame}{Library learning}
  \Wider[5em]{
    \begin{center}
      \begin{tabular}{cc}
        \includegraphics[height=\textheight]{figures/figureOneFinal1_primitives}&
        \includegraphics[height=\textheight]{figures/figureOneFinal1_problem}
      \end{tabular}
    \end{center}
  }
  \myPaper{Ellis, Morales, Sable-Meyer, Solar-Lezama, Tenenbaum. NeurIPS 2018.\\
    Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}[t]{Library learning}
\Wider[5em]{  \begin{center}
    \begin{tabular}{ccc}
      \includegraphics[height=0.6\textheight]{figures/figureOneFinal1_primitives}&
      \phantom{testingtesting}&
      \includegraphics[height=0.6\textheight]{figures/figureOneFinal1_problem}
    \end{tabular}
\end{center}}
\myPaper{Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}


\begin{frame}{Library learning}
%  \centering
  
  \only<1>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal1}}}
  \only<2>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_layer1}}}
  \only<3>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_layer1_exploded}}}
  \only<4>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_layer1}}}
  \only<5>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_layer2}}}
  \only<6>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_layer2_exploded}}}
  \only<7>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_layer2}}}
  \only<8>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2}}}
  \only<9>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal2_exploded}}}
  \only<10>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal3}}}
  \only<11>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal3_explained_exploded}}}
  \only<12->{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal3_explained}}}
%  \only<12>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal4}}}
  %  \only<5>{  \Wider[5em]{\includegraphics[width = \textwidth]{figures/figureOneFinal5}}}

  \visible<12->{Solution rewritten in initial primitives:

    \tiny\texttt{(lambda (x) (map (lambda (y) (car (fold (fold x nil (lambda (z u) (if (gt? (+ y 1) (length (fold x nil (lambda (v w) (if (gt? z v) (cons v w) w))))) (cons z u) u))) nil (lambda (a b) (if (nil? (fold (fold x nil (lambda (c d) (if (gt? (+ y 1) (length (fold x nil (lambda (e f) (if (gt? c e) (cons e f) f))))) (cons c d) d))) nil (lambda (g h) (if (gt? g a) (cons g h) h)))) (cons a b) b))))) (range (length x))))}}

  \visible<13>{\normalsize induced sort program found in $\leq 10$min. Brute-force search without learned library would take $\approx 10^{73}$ years }

%  \myPaper{Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  
\end{frame}

\begin{frame}{DreamCoder}
  \begin{itemize}
  \item   \textbf{Wake:} Solve problems by writing programs
  \item \textbf{Sleep:} Improve library and neural recognition model:
    \begin{itemize}
    \item \textbf{Abstraction sleep:} Improve library
      \item \textbf{Dream sleep:} Improve neural recognition model
    \end{itemize}
%  \item   Combines ideas from Wake-Sleep \& Exploration-Compression % \& Program analysis
  \end{itemize}
  \Wider[5.4em]{
    \begin{center}
      \begin{tikzpicture}
    \visible<2->{
      \node(Lisp) at (-3,0) {\includegraphics[width = 0.8\textwidth]{figures/manyDomains_child.png}};
    }
    \node at (0.8,1.3) {  \includegraphics[width = 4cm]{ecFigures/sleepingChild.jpg}};
  \end{tikzpicture}
        \end{center}}

\hspace*{-0.4cm}\small cf. Helmholtz machine, wake/sleep neural network training algorithms
\end{frame}
\begin{frame}[t]{Library learning as Bayesian inference}
  %  \includegraphics[width = 11cm]{ecFigures/animation/EC.eps}
\centering  \begin{tikzpicture}[scale=1.3,line width=0.5mm]

  \node[latent,scale=1] at (3.5,3) (dx){Library};
  \node[latent,scale=1] at ([yshift=-1.5cm]dx) (zp){prog};
  \node[obs,scale=1] at ([yshift=-2cm]zp) (xp) {task};
  \node[latent,scale=1] at ([xshift=2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=2cm]xp) (xp1) {task};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
  %\draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};
  % HACK : "invisible" arrow to phantom and push to the left and align with next
  % slide
  \draw [->,red,opacity=0.0001] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
  
  \node[latent,scale=1] at ([xshift=-2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=-2cm]xp) (xp1) {task};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
%  \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};


%  \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
 % \node at (nn) {\NeuralNetwork{0.5}};
  \draw [->] (dx.south) -- (zp.north);
  \draw [->] (zp.south) -- (xp.north);


  %\node[shift={+(0,-1.7)}] at (nn) { $Q$  };

  \end{tikzpicture}
  

\vspace{0.5cm}
  
[Dechter et al, 2013]  [Liang et al, 2010] [Lake et al, 2015]

%\textbf{Dechter et al.}: Exploration-Compression. Inspiration for DreamCoder.

  %% \vfill
  %% Gray: Observed.\\
  %% White: Latent.\\
  %% Boxed (plate): Repeated.\\
  
\end{frame}
\newcommand{\NeuralNetwork}[1]{    \begin{tikzpicture}[x=2.5cm,y=1.25cm,transform canvas={scale=#1,shift={+(-1,2.5)}}]
      \tikzstyle{neuron}=[circle,fill=blue!50,minimum size=20pt]
      \fill[fill=white] (-0.25,-0.5) rectangle (2.25,-4.5);
      \node[rectangle] at (1,1) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (I-\name) at (0,-\y) {};
      \foreach \name / \y in {1,...,3}
          \node[neuron] (H-\name) at (1,-\y-0.5) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (O-\name) at (2,-\y) {};
      \foreach \source in {1,...,4}
          \foreach \dest in {1,...,3}
              \draw [-latex] (I-\source) -- (H-\dest);
      \foreach \source in {1,...,3}
          \foreach \dest in {1,...,4}
              \draw [-latex] (H-\source) -- (O-\dest);
    \end{tikzpicture}}
\begin{frame}[t]{Library learning as \alert{neurally-guided} Bayesian inference}
\centering  \begin{tikzpicture}[scale=1.3,line width=0.5mm]

  \node[latent,scale=1] at (3.5,3) (dx){Library};
  \node[latent,scale=1] at ([yshift=-1.5cm]dx) (zp){prog};
  \node[obs,scale=1] at ([yshift=-2cm]zp) (xp) {task};
  \node[latent,scale=1] at ([xshift=2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=2cm]xp) (xp1) {task};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
  \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};
  
  \node[latent,scale=1] at ([xshift=-2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=-2cm]xp) (xp1) {task};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
  \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};


  \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
  \node at (nn) {\NeuralNetwork{0.25}};
  \draw [->] (dx.south) -- (zp.north);
  \draw [->] (zp.south) -- (xp.north);


  %\node[shift={+(0,-1.7)}] at (nn) { $Q$  };

\end{tikzpicture}


\Wider[4em]{
  \begin{center}
    library learning via program analysis + \\
    new neural inference network for program synthesis + \\
    better program representation (Lisp+polymorphic types [Milner 1978])
  \end{center}
}
%\myPaper{Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}
\newcommand{\NeuralNetwork}[1]{    \begin{tikzpicture}[x=2.5cm,y=1.25cm,transform canvas={scale=#1,shift={+(-1,2.5)}}]
      \tikzstyle{neuron}=[circle,fill=blue!50,minimum size=20pt]
      \fill[fill=teal!5!white] (-0.25,-0.5) rectangle (2.25,-4.5);
      \node[rectangle] at (1,1) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (I-\name) at (0,-\y) {};
      \foreach \name / \y in {1,...,3}
          \node[neuron] (H-\name) at (1,-\y-0.5) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (O-\name) at (2,-\y) {};
      \foreach \source in {1,...,4}
          \foreach \dest in {1,...,3}
              \draw [-latex] (I-\source) -- (H-\dest);
      \foreach \source in {1,...,3}
          \foreach \dest in {1,...,4}
              \draw [-latex] (H-\source) -- (O-\dest);
    \end{tikzpicture}}
\newcommand{\spiral}[2]{
  \draw[ultra thick,->] ([shift={#1}]-30:#2) arc [radius = #2, start angle = -30, end angle = 90];
  \draw[ultra thick,->] ([shift={#1}]-30:#2) arc [radius = #2, start angle = -30, end angle = 95];

  
      \draw[ultra thick,->] ([shift={#1}]90:#2) arc [radius = #2, start angle = 90, end angle = 210];
      \draw[ultra thick,->] ([shift={#1}]90:#2) arc [radius = #2, start angle = 90, end angle = 205];
      
      \draw[ultra thick,->] ([shift={#1}]210:#2) arc [radius = #2, start angle = 210, end angle = 340];
      \draw[ultra thick,->] ([shift={#1}]210:#2) arc [radius = #2, start angle = 210, end angle = 335];
}
\newcommand{\legend}{
  \begin{tikzpicture}
    \node at (0,0) (uses){is};
    \draw[->,red] ([xshift=-0.6cm]uses.west)  -- (uses.west);
    \node at ([xshift=0.4cm]uses.east) {\NeuralNetwork{0.15}};
    \draw[thin] (-1,-0.4) rectangle (1.2,0.4);
  \end{tikzpicture}
}

\begin{frame}{}
%  \myPaper{\footnotesize Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  \centering
  \only<1>{

    \vspace{3cm}

    

    \hspace*{1cm}\includegraphics[width = 0.3\textwidth]{cycleGraphicalModel1}}
  \only<2>{\includegraphics[width = \textwidth]{cycleGraphicalModel2}}
  \only<3>{\includegraphics[width = \textwidth]{cycleGraphicalModel3}}
  \only<4>{\includegraphics[width = \textwidth]{cycleGraphicalModel4}}
  \only<5>{\includegraphics[width = \textwidth]{cycleGraphicalModel5}}
  \only<6>{\includegraphics[width = \textwidth]{cycleGraphicalModelAbstraction}}
\end{frame}

%% \begin{frame}{DreamCoder's sleep cycles}
%% \tiny\begin{tikzpicture}[scale=0.55,line width=0.25mm]
%%     \draw[fill=teal!5!white] (-1.25,1.25) -- (13.25,1.25) -- (13.25,-4) -- (-1.25,-4) -- (-1.25,1.25);
%%     \node at (5.5,1.5) {\textsc{\textbf{Wake}}};

    
%%     \begin{scope}[shift={(0.5,0.5)}]
%%       \node[align=center] at (0,-0.5) (d){
%%         \begin{tabular}{l}
%%           \multicolumn{1}{c}{\textbf{Library}}\\
%%         \texttt{$f_1($x$)=$(+ x 1)}\\
%%         \texttt{$f_2($z$)=$(fold cons}\\
%%         \phantom{\texttt{$f_2($z$)$}}\texttt{(cons z nil))}\\
%%  $\cdots\cdots\cdots$
%%                 \end{tabular}};
%%       \node[align=center] at ([yshift = -2cm]d) (t){\textbf{Task}\\
%%                     \texttt{[7\, 2\, 3]}$\to$\texttt{[4 3 8]}         \\
%%             \texttt{[3\, 8]}$\to$\texttt{[9 4]}\\
%%             \texttt{[4\, 3\, 2]}$\to$\texttt{[3 4 5]} };

%%       \node at ([xshift = 1.25cm]t.east) (nn){\NeuralNetwork{0.1}};
%%       \node[align = center, text width = 1cm] at ([yshift = 0.7cm,xshift=0cm]nn.north) {\baselineskip=0pt  Recog. model\par};
%%       \draw [red,-{>[scale=0.2]}] (t.east) -- ([xshift = -0.5cm]nn.west);

%%       \node[draw,rounded corners, align=center, inner sep = 5] at ([xshift = 4.2cm,yshift = 1cm]t.east) (s){Neurally-Guided\\ Enumerative Search};

%%       \draw [red,->] ([xshift = 0.5cm]nn.east) -- ([yshift = -0.25cm]s.west);
%%       \draw [->,rounded corners,] (d.east) -- ([yshift = 2cm]nn.center) -- ([yshift = 0.25cm]s.west);

%%       \node[align=left] at ([xshift=3cm]s.east) (f) {\textbf{Programs for task:}\\
%%             \texttt{(map $f_1$ (fold $f_2$ nil x))}\\
%%          $\cdots\cdots\cdots$};
%%       \draw [->  ] (s.east) -- (f.west);

%%       \draw [->  ,rounded corners] (t.south) -- ([yshift = -0.5cm]t.south) -- ([yshift = -0.5cm] s.south |- t.south) -- (s.south);
%%     \end{scope}
    
%%     \begin{scope}[shift={(9.4,-3.5)},scale=0.6,line width=0.05mm]
%%       \node[obs,scale=0.7] at (3.5,3) (dx){Library};
%%       \node[latent,scale=0.7] at ([yshift=-1.7cm,xshift=0cm]dx) (zp){prog};
%%       \node[obs,scale=0.7] at ([yshift=-1.45cm]zp) (xp) {task};
%%       \node[latent,scale=0.7] at ([xshift=1.5cm]zp) (zp1){prog};
%%       \node[obs,scale=0.7] at ([xshift=1.5cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%       \node[latent,scale=0.7] at ([xshift=-1.5cm]zp) (zp1){prog};
%%       \node[obs,scale=0.7] at ([xshift=-1.5cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->] (dx.south) -- (zp.north);
%%       \draw [->] (zp.south) -- (xp.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%       \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
%%     \end{scope}


%%     \node at (0,-4.75) {\textbf{\textsc{Sleep: Abstraction}}};
%%     \draw[fill=teal!5!white] (-3,-5) -- (3,-5) -- (3,-10) -- (5.5,-10) -- (5.5,-13) -- (-3,-13) -- (-3,-5);
%%     \node at (12,-4.75) {\textbf{\textsc{Sleep: Dreaming}}};
%%     \draw[fill=teal!5!white] (15,-5) -- (9,-5) -- (9,-10) -- (6.5,-10) -- (6.5,-13) -- (15,-13) -- (15,-5);

%%     \begin{scope}[shift={(9.5,-4.5)}]
%%       \node(dreaming) at (1,-1) {\underline{Fantasies}};
%%       \node[anchor=center] at ([yshift=-0.5cm]dreaming.south) (d){\textbf{Library}};
%%       \node at ([yshift=-1.75cm]d.south) (p1){program};
%%       \draw[squiggle,-> ] (d.south) -- node[sloped,above]{{ sample}} (p1.north);

%%       \node(replay) at ([xshift=2cm]dreaming.east) {\underline{Replays}};
%%       \node[anchor=center,align=center] at ([yshift=-0.5cm]replay.south) (d){\textbf{progs. for task}};
%%       \node at ([yshift=-1.75cm]d.south) (p1){program};
%%       \draw[squiggle,-> ] (d.south) -- node[sloped,above]{ sample} (p1.north);

%%       \node(p1) at (1.5,-6) {program};      
%%       \node at ([xshift = 2.0cm]p1.east) (t1){ task};
%%       \draw [-> ] (p1.east) -- node[above]{ run} (t1.west);
%%       \node(n) at ([yshift=-1.2cm,xshift=1.25cm]p1.south) {
%%         \NeuralNetwork{0.17}};
%%       \draw [->,red] (t1.south) to[out = -90,in = 0]  ([xshift=0.4cm]n.east);
%%       \draw [dashed] (p1.south) to[out=-120,in=180] node[above,fill=teal!5!white]{\color{black}Loss} ([xshift=-0.4cm]n.west);


%%       \node at ($(-0.25,0.5) + (p1.north)!0.5!(t1.north)$) {\underline{Train recognition model}};

%%       %% \node at ([xshift = 1.5cm]p1.east) (t1){ task};
%%       %% \draw [-> ] (p1.east) -- node[above]{ run} (t1.west);
%%       %% \node(n) at ([yshift=-1.2cm,xshift=0.4cm]p1.south) {
%%       %%   \NeuralNetwork{0.17}};
%%       %% \draw [->,red] (t1.south) to[out = -90,in = 0]  ([xshift=0.4cm]n.east);
%%       %% \draw [dashed] (p1.south) to[out=-120,in=180] node[above,fill=white]{\color{black}Loss} ([xshift=-0.4cm]n.west);

%%       \begin{scope}[shift={(-3.8,-8)},scale=0.6,line width=0.05mm]
%%         \node[obs,scale=0.4] at (3.5,3) (dx){L};
%%         \node[obs,scale=0.4] at ([yshift=-1.7cm,xshift=0cm]dx) (zp){p};
%%         \node[obs,scale=0.4] at ([yshift=-1.45cm]zp) (xp) {t};
%%         \node[obs,scale=0.4] at ([xshift=1.5cm]zp) (zp1){p};
%%         \node[obs,scale=0.4] at ([xshift=1.5cm]xp) (xp1) {t};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%         \node[obs,scale=0.4] at ([xshift=-1.5cm]zp) (zp1){p};
%%         \node[obs,scale=0.4] at ([xshift=-1.5cm]xp) (xp1) {t};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \draw [->] (dx.south) -- (zp.north);
%%         \draw [->] (zp.south) -- (xp.north);
%%         \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%         \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
%%       \end{scope}


%%       \end{scope}

%%     % memory consolidation
%%     \begin{scope}[shift={(-2,-4.5)}]

%%       %% defined routines for creating fragmented syntax trees
%%       \newcommand{\syntaxOne}[1]{
%%         \begin{tikzpicture}[scale=#1,line width=0.35mm]          
%%           \node(l1) at (0,0) {};
%%           \node[color=pop3](p1) at (-1,-1) {\texttt{+}};
%%           \node[color=pop3](n1) at (0.7,-0.9) {\texttt{1}};
%%           \node(x1) at (0,-1) {\texttt{1}};
%%           \draw[color=pop3] (l1.south) -- (p1.north);
%%           \draw[color=pop3] (l1.south) -- (n1.north);
%%           \draw[color=pop3] (-0.5,-0.45) -- (x1.north);

%%           \node(t) at (-0.5,0.5) {};
%%           \draw (l1.south) -- (t.south);
%%           \node(c) at (-1.5,-0.2) {\texttt{cons}};
%%           \draw (t.south) -- (c.north);
%%         \end{tikzpicture}
%%       }
%%       \newcommand{\syntaxTo}[1]{
%%         \begin{tikzpicture}[scale=#1,line width=0.35mm]          
%%             \node(l1) at (0,0) {};
%%             \node[color=pop3](p1) at (-1,-1) {\texttt{+}};
%%             \node[color=pop3](n1) at (0.7,-0.9) {\texttt{1}};
%%             \draw[color=pop3] (l1.south) -- (p1.north);
%%             \draw[color=pop3] (l1.south) -- (n1.north);
%%             \draw[color=pop3] (-0.5,-0.45) -- (0,-1);
%%             \node(c) at (-0.5,-1.5) {\texttt{car}};
%%             \node(z) at (0.5,-1.5) {\texttt{z}};
%%             \draw (0,-1) -- (c.north);
%%             \draw (0,-1) -- (z.north);
%%         \end{tikzpicture}
%%       }

%%       \node[align=center,anchor=center] at (0.4,-1.2) (f1){\textbf{ progs. for task 1}:\\\texttt{(+ (car z) 1)}};
%%       \node[align=center] at ([xshift = 1.75cm]f1.east) (f2){\textbf{  progs. for task 2}:\\\texttt{(cons (+ 1 1))}};
%%       \node(s1) at ([yshift=-0.5cm]f1.south) {\syntaxOne{0.5}};
%%       \node(s2) at ([yshift=-0.5cm]f2.south) {\syntaxTo{0.5}};
%%       \node(c)[align=center,rectangle, rounded corners, draw, minimum width = 1cm, minimum height = 0.5cm, anchor = north] at ($(s1.south)!0.5!(s2.south) + (0,-1)$) {Refactoring Algorithm};
%%       \draw [-> ] (s1.south) -- (s1.south|-c.north);
%%       \draw [-> ] (s2.south) -- (s2.south|-c.north);

      
%%       \node(d) at ([yshift = -1.8cm]c.south) {
%%         \begin{tikzpicture}[scale=0.5,line width=0.5mm]
%%           \node[align=center] at (0,0) {\textbf{new Library} w/ \texttt{(+ x 1)}:};
%%           \begin{scope}[shift={(0.6,-0.5)}]
%%             \node[pop3](p1) at (-1,-1) {\texttt{+}};
%%             \node[pop3](n1) at (0.6,-0.9) {\texttt{1}};
%%             \node[pop3](a) at (0,-1) {\texttt{ }};
%%             \draw[pop3] (0,0) -- (p1.north);
%%             \draw[pop3] (0,0) -- (n1.north);
%%             \draw[pop3] (-0.3,-0.3) -- (a.north);
%%           \end{scope}
%%       \end{tikzpicture}};
%%       \draw [-> ] (c.south) -- (d.north);



%%       \begin{scope}[shift={(4,-8)},scale=0.6,line width=0.05mm]
%%         \node[latent,scale=0.7] at (3.5,3) (dx){Library};
%%         \node[obs,scale=0.7] at ([yshift=-1.7cm,xshift=0cm]dx) (zp){prog};
%%         \node[obs,scale=0.7] at ([yshift=-1.45cm]zp) (xp) {task};
%%         \node[obs,scale=0.7] at ([xshift=1.5cm]zp) (zp1){prog};
%%         \node[obs,scale=0.7] at ([xshift=1.5cm]xp) (xp1) {task};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \node[obs,scale=0.7] at ([xshift=-1.5cm]zp) (zp1){prog};
%%         \node[obs,scale=0.7] at ([xshift=-1.5cm]xp) (xp1) {task};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \draw [->] (dx.south) -- (zp.north);
%%         \draw [->] (zp.south) -- (xp.north);
%%       \end{scope}


%%       \end{scope}


    
%%     %% center spiral
%%     \begin{scope}[shift={(3.25,-7.9)},scale=0.8]    
%%       \spiral{(3.5,1)}{3.5}
%%       \node[latent,scale=1] at (3.5,3) (dx){Library};
%%       \node[latent,scale=1] at ([yshift=-2cm,xshift=0cm]dx) (zp){prog};
%%       \node[obs,scale=1] at ([yshift=-1.45cm]zp) (xp) {task};
%%       \node[latent,scale=1] at ([xshift=2cm]zp) (zp1){prog};
%%       \node[obs,scale=1] at ([xshift=2cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
      
%%       \node[latent,scale=1] at ([xshift=-2cm]zp) (zp1){prog};
%%       \node[obs,scale=1] at ([xshift=-2cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);


%%       \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
%%       \draw [->] (dx.south) -- (zp.north);
%%       \draw [->] (zp.south) -- (xp.north);

%%       \node at ([yshift=-0.6cm]xp.south) {\legend};

%%     \end{scope}    
%%   \end{tikzpicture}  

%% \end{frame}

%% \begin{frame}{}
%%   \only<1>{\includegraphics[width = \textwidth]{figures/compressionAnimation/1.jpg}}
%%   \only<2>{\includegraphics[width = \textwidth]{figures/compressionAnimation/2.jpg}}
%%   \only<3>{\includegraphics[width = \textwidth]{figures/compressionAnimation/3.jpg}}
%%   \only<4>{\includegraphics[width = \textwidth]{figures/compressionAnimation/4.jpg}}
%%   \only<5>{\includegraphics[width = \textwidth]{figures/compressionAnimation/5.jpg}}
%% %  \only<6>{\includegraphics[width = \textwidth]{figures/compressionAnimation/6.jpg}}
%%   \only<7>{\includegraphics[width = \textwidth]{figures/compressionAnimation/7.jpg}}
%%   \only<8>{\includegraphics[width = \textwidth]{figures/compressionAnimation/8.jpg}}
%%   \only<9>{\includegraphics[width = \textwidth]{figures/compressionAnimation/9.jpg}}
%%   \only<10>{\includegraphics[width = \textwidth]{figures/compressionAnimation/10.jpg}}
%%   \only<11>{\includegraphics[width = \textwidth]{figures/compressionAnimation/11.jpg}}
%%   \only<12>{\includegraphics[width = \textwidth]{figures/compressionAnimation/12.jpg}}
%%   \only<13>{\includegraphics[width = \textwidth]{figures/compressionAnimation/13.jpg}}
%%   \only<14>{\includegraphics[width = \textwidth]{figures/compressionAnimation/14.jpg}}
%%   \only<15>{\includegraphics[width = \textwidth]{figures/compressionAnimation/15.jpg}}
%%   \only<16>{\includegraphics[width = \textwidth]{figures/compressionAnimation/16.jpg}}
%%   \only<17>{\includegraphics[width = \textwidth]{figures/compressionAnimation/17.jpg}}
%%   \only<18>{\includegraphics[width = \textwidth]{figures/compressionAnimation/18.jpg}}
%%   \only<19>{\includegraphics[width = \textwidth]{figures/compressionAnimation/19.jpg}}
%%   \only<20>{\includegraphics[width = \textwidth]{figures/compressionAnimation/20.jpg}}
%%   \only<21>{\includegraphics[width = \textwidth]{figures/compressionAnimation/21.jpg}}
%%   \only<22>{\includegraphics[width = \textwidth]{figures/compressionAnimation/22.jpg}}
%%   \only<23>{\includegraphics[width = \textwidth]{figures/compressionAnimation/23.jpg}}
%%   \only<24>{\includegraphics[width = \textwidth]{figures/compressionAnimation/24.jpg}}
%%   \only<25>{\includegraphics[width = \textwidth]{figures/compressionAnimation/25.jpg}}
%%   \only<26>{\includegraphics[width = \textwidth]{figures/compressionAnimation/26.jpg}}
%% \end{frame}
\newcommand{\abstractionTree}[2]{
  \smallTree{#1}{#2}{+}{$x$}{$x$};
  \node(a#1) at ([yshift=0.5cm]root#1.south) {$\lambda x$};

  \draw (a#1.south) -- (root#1.south);  
  }
\newcommand{\smallTree}[5]{
  \node(root#1) at (#2) {};
  \node[anchor=north](r#1) at ([xshift=0.5cm,yshift=-0.5cm]root#1) {#5};
  \node(l#1) at ([xshift=-0.5cm,yshift=-0.5cm]root#1) {};
  \node(ll#1) at ([xshift=-0.5cm,yshift=-0.5cm]l#1) {#3};
  \node(lr#1) at ([xshift=0.5cm,yshift=-0.5cm]l#1) {#4};

  \draw (root#1.south) -- (r#1.north);
  \draw (root#1.south) -- (l#1.north);
  \draw (l#1.north) -- (ll#1.north);
  \draw (l#1.north) -- (lr#1.north);
}
\newcommand{\appliedTree}[6]{
  \smallTree{#1}{#2}{#3}{#4}{#5};
  \node(a#1) at ([yshift=0.5cm]root#1.south) {$\lambda x$};
  \node(ar#1) at ([xshift=0.5cm,yshift=0.4cm]a#1.north) {};
  \node[anchor=north](argument#1) at ([xshift=1cm]a#1.north) {#6};

  \draw (a#1.south) -- (root#1.south);
  \draw (argument#1.north) -- (ar#1.south);
  \draw (a#1.north) -- (ar#1.south);
}
\newcommand{\chooseAny}[4]{
  \node[anchor=north](any#1) at (#2) {\textsc{\small Any}};
  \node(anyl#1) at ([xshift=-0.25cm,yshift=-0.5cm]any#1.south) {#3};
  \node(anyr#1) at ([xshift=0.25cm,yshift=-0.5cm]any#1.south) {#4};
  \draw (any#1.south)--(anyl#1.north);
  \draw (any#1.south)--(anyr#1.north);  
}
\newcommand{\chooseTreeTiny}[3]{
  \node(a#1) at (#2) {$\lambda z$};
  \node(ar#1) at ([xshift=0.5cm,yshift=0.4cm]a#1.north) {};
  \node[anchor=north](argument#1) at ([xshift=1cm]a#1.north) {#3};

  \chooseAny{any#1}{[yshift=-0.2cm]a#1.south}{#3}{$z$}

  \draw (a#1.south) -- (anyany#1.north);
  \draw (argument#1.north) -- (ar#1.south);
  \draw (a#1.north) -- (ar#1.south);
}  

\newcommand{\chooseTreeSmall}[7]{
  \node(root#1) at (#2) {};
  \node[anchor=north](r#1) at ([xshift=0.5cm,yshift=-0.5cm]root#1) {#5};
  \node(l#1) at ([xshift=-0.5cm,yshift=-0.5cm]root#1) {};
  \chooseAny{any#1}{[xshift=-0.5cm,yshift=-0.5cm]l#1}{#3}{#4};
  \draw (l#1.north) -- (anyany#1.north);
%  \node(ll#1) at ([xshift=-0.5cm,yshift=-0.5cm]l#1) {};
  \node(lr#1) at ([xshift=0.5cm,yshift=-0.5cm]l#1) {#5};

  \draw (root#1.south) -- (r#1.north);
  \draw (root#1.south) -- (l#1.north);
  \draw (l#1.north) -- (lr#1.north);

  \node(a#1) at ([yshift=0.5cm]root#1.south) {$\lambda y$};
  \node(ar#1) at ([xshift=0.5cm,yshift=0.4cm]a#1.north) {};
  \node[anchor=north](argument#1) at ([xshift=1cm]a#1.north) {#7};

  \draw (a#1.south) -- (root#1.south);
  \draw (argument#1.north) -- (ar#1.south);
  \draw (a#1.north) -- (ar#1.south);
}
\newcommand{\chooseTree}[6]{
  \node(root#1) at (#2) {};
  \chooseAny{anyl#1}{[xshift=1cm,yshift=-0.8cm]root#1}{#4}{#5};
  \draw (root#1.south) -- (anyanyl#1.north);  
  \node(l#1) at ([xshift=-0.75cm,yshift=-0.75cm]root#1) {};
  \node(ll#1) at ([xshift=-0.75cm,yshift=-0.75cm]l#1) {#3};
  \chooseAny{anyr#1}{[xshift=0.5cm,yshift=-0.5cm]l#1}{#4}{#5};
  \draw (l#1.north) -- (anyanyr#1.north);

  \draw (root#1.south) -- (l#1.north);
  \draw (l#1.north) -- (ll#1.north);


  \node(a#1) at ([yshift=0.5cm]root#1.south) {$\lambda x$};
  \node(ar#1) at ([xshift=0.5cm,yshift=0.4cm]a#1.north) {};
  \node[anchor=north](argument#1) at ([xshift=1cm]a#1.north) {#6};

  \draw (a#1.south) -- (root#1.south);
  \draw (argument#1.north) -- (ar#1.south);
  \draw (a#1.north) -- (ar#1.south);
}
\newcommand{\chooseTreeCompact}[6]{
  \node(root#1) at (#2) {};
  \chooseAny{anyl#1}{[xshift=0.75cm,yshift=-0.5cm]root#1}{#4}{#5};
  \draw (root#1.south) -- (anyanyl#1.north);  
  \node(l#1) at ([xshift=-0.5cm,yshift=-0.5cm]root#1) {};
  \node(ll#1) at ([xshift=-0.5cm,yshift=-0.5cm]l#1) {#3};
  \chooseAny{anyr#1}{[xshift=0.3cm,yshift=-0.3cm]l#1}{#4}{#5};
  \draw (l#1.north) -- (anyanyr#1.north);

  \draw (root#1.south) -- (l#1.north);
  \draw (l#1.north) -- (ll#1.north);


  \node(a#1) at ([yshift=0.5cm]root#1.south) {$\lambda x$};
  \node(ar#1) at ([xshift=0.5cm,yshift=0.4cm]a#1.north) {};
  \node[anchor=north](argument#1) at ([xshift=1cm]a#1.north) {#6};

  \draw (a#1.south) -- (root#1.south);
  \draw (argument#1.north) -- (ar#1.south);
  \draw (a#1.north) -- (ar#1.south);
}
  
  
%% \begin{frame}[fragile]{Abstraction Sleep: Growing the library via refactoring}
%%   $5 + 5$\\\pause\texttt{(+ 5 5)}\pause

%%   \vspace*{-0.5cm}\begin{center}
%%     \begin{tikzpicture}[scale=1]
%%       \smallTree{start}{0,0}{+}{5}{5};
%%     \end{tikzpicture}
%%   \end{center}
%% \end{frame}

%% \begin{frame}[fragile]{Abstraction Sleep: Growing the library via refactoring}
%%   \centering
%%   \begin{tikzpicture}[scale=1]
%%     \smallTree{start}{0,0}{+}{5}{5};
%%     \pause
%%     \appliedTree{r1}{4,-0.5}{+}{5}{$x$}{5};
%%     \pause
%%     \appliedTree{r2}{0,2}{$+$}{$x$}{5}{5};
%%     \pause
%%     \appliedTree{r3}{-4,-0.5}{$+$}{$x$}{$x$}{5};
%%     \pause
%%     \appliedTree{r4}{0,-3}{$+$}{5}{5}{5};
%%     \pause

%%     \draw [*-*,dashed,orange, very thick](rootstart.south) to[out=10,in=150] (arr1.south);
%%     \draw [-*,dashed,orange, very thick](rootstart.south) to[out=20,in=-90] ([xshift=2cm,yshift=-1cm]arr2.south) to[out=90,in=10] (arr2.south);
%%     \draw [-*,dashed,orange, very thick](rootstart.south) to[out=160,in=30] (arr3.south);
%%     \draw [-*,dashed,orange, very thick](rootstart.south) to[out=20,in=0] (arr4.south);

%%     \node[anchor=south west](legend) at (-5,2.5) {legend};
%%     \draw [dashed,orange, very thick]([xshift=0.1cm,yshift=-0.2cm]legend.south west)--([yshift=-0.2cm,xshift=0.5cm]legend.south west);
%%     \node(se)[anchor=west] at ([yshift=-0.2cm,xshift=0.5cm]legend.south west) {\small semantic equivalence};
%%     \draw[rounded corners] (legend.north west) rectangle (se.south east);

%%     \node[anchor=west,align=left] at (-5.5,-3.25) {\small cf. [Tate, Stepp, \\\small\phantom{cf. [}Tatlock, Lerner 2009]
%%       %[Downey et al. 1980]
%%       };
    
%%   \end{tikzpicture}
  
%%   \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
%% \end{frame}

%% \begin{frame}[fragile,noframenumbering]{Abstraction Sleep: Growing the library via refactoring}
%% \Wider[4em]{  \begin{tikzpicture}
%%     \node[anchor=south west](legend) at (-5,2) {legend};
%%     \draw [dashed,orange, very thick]([xshift=0.1cm,yshift=-0.2cm]legend.south west)--([yshift=-0.2cm,xshift=0.9cm]legend.south west);
%%     \node(se)[anchor=west] at ([yshift=-0.2cm,xshift=0.9cm]legend.south west) {\small semantic equivalence};
%%     \node[anchor=west](choosing) at ([yshift=-0.6cm]legend.south west) {{\textsc{\small Any}} \small nondeterministic choice};
%%     \draw[rounded corners] (legend.north west) rectangle (choosing.south east);

%%     \smallTree{start}{0,0}{+}{5}{5};
%%     \chooseTree{L}{4,-1}{+}{5}{$x$}{5};
%%     \draw [*-*,dashed,orange, very thick] (rootstart.south)    -- (arL.south);

%%     \node[align=left,anchor=west] at (-5.75,-4.5) {\small cf. [Lau, Wolfman, \\\small\phantom{cf. [}Domingos, Weld '02]\\\phantom{t}};%\\\small\phantom{cf. }Liang et al. 2010};

%%     \pause

%%     \chooseTreeSmall{R}{-4,-1}{+}{$y$}{5}{5}{+};
%%     \draw [-*,dashed,orange, very thick] (rootstart.south)    -- (arR.south);

%%     \pause

%%     \chooseTreeTiny{fiber}{0,-2.75}{5};
    
%%     \draw [-*,dashed,orange, very thick] (rstart.south)    -- (arfiber.south);
%%     \draw [dashed,orange, very thick] (lrstart.south)    -- (arfiber.south);
%%     \draw [dashed,orange, very thick] (rR.east)    -- (arfiber.south);
%%     \draw [dashed,orange, very thick] (lrR.south east)    -- (arfiber.south);

%%     \pause

%%     \node[inner sep=0pt,dotted,very thick,label=below:{2 choices},fit=(anyanyfiber)(anylanyfiber)(anyranyfiber),draw] {};
%%     \node[inner sep=0pt,dotted,very thick,label=below:{2 choices},fit=(anyanyR)(anylanyR)(anyranyR),draw] {};
%%     \node[inner sep=0pt,dotted,very thick,label=below:{2 choices},fit=(anyanylL)(anyranylL)(anylanylL),draw] {};
%%     \node[inner sep=0pt,dotted,very thick,label=below:{2 choices},fit=(anyanyrL)(anyranyrL)(anylanyrL),draw] {};

%%     \pause
%%     \node at (arL.north) {\small $2\times 2=4$ choices};
%%     \node at (arR.north) {\small $2\times 2\times 2=8$ choices};
%%     \node at (rootstart.north) {\small $2\times 2=4$ choices};
%% %    \node[inner sep=0pt,dotted,very thick,label=above:{$2\times 2=4$ choices},fit=(choiceLabelA)(choiceLabelB),draw] {};
    
%% \end{tikzpicture}}
%%   \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
%% \end{frame}

%% \begin{frame}[fragile]{}
%%   \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}%
%%   \Wider[4em]{  \vspace*{-0.5cm}\begin{tikzpicture}
%% %      \node[align=left,anchor=south west] at (7,-9) {\small Ellis et al. 2020.};
%%     \node[anchor=south west](legend) at (-1,-8) {legend};
%%     \draw [dashed,orange, very thick]([xshift=0.1cm,yshift=-0.1cm]legend.south west)--([yshift=-0.1cm,xshift=0.9cm]legend.south west);
%%     \node(se)[anchor=west] at ([yshift=-0.1cm,xshift=0.9cm]legend.south west) {\small semantic equivalence};
%%     \node[anchor=west](choosing) at ([yshift=-0.5cm]legend.south west) {{\textsc{\small Any}} \small nondeterministic choice};
%%     \draw[rounded corners] (legend.north west) rectangle (choosing.south east);
    
%%     \smallTree{original}{0,0}{+}{5}{5};
%%     \chooseTreeCompact{originalSpace}{3,-1}{+}{5}{$x$}{5};
%%     \draw [*-*,dashed,orange, very thick] (rootoriginal.south)    -- (aroriginalSpace.south);

%%     \smallTree{remix}{0,-4}{+}{4}{4};
%%     \chooseTreeCompact{remixSpace}{3,-5}{+}{4}{$x$}{4};
%%     \draw [*-*,dashed,orange, very thick] (rootremix.south)    -- (arremixSpace.south);

%%     \pause

%%     \draw[very thick] ([yshift=-1cm]rootremixSpace.north) circle (1.4cm);
%%     \draw[very thick] ([yshift=-1cm]rootoriginalSpace.north) circle (1.4cm);
%%     \node at ([xshift=1.5cm,yshift=-0.2cm]rootoriginalSpace.north) {\textbf{``A''}};
%%     \node at ([xshift=1.5cm,yshift=-0.2cm]rootremixSpace.north) {\textbf{``B''}};

%%     \pause

%%     \abstractionTree{common}{8,-1};
%%     \node[anchor=south] at (acommon.north) {\textbf{A intersect B:}};%$\mathbf\cap$\textbf{B is:}};

%%     \pause

%%     \node(python) at (lrcommon.south) {$\underbrace{\phantom{testingtestinging}}_{\text{\texttt{(lambda (x) (+ x x))}}}$};

%%     \pause

%%     \node(double)[anchor=north] at (python.south) {$=$\texttt{ double}};

%%     \pause

%%     \node[anchor=north] at ([yshift=-1cm]double.south) {
%%         \begin{tabular}{ll}
%%           w/o \texttt{double}&w/ \texttt{double}\\\midrule 
%%           \texttt{(+ 5 5)}&\texttt{(double 5)}\\
%%           \texttt{(+ 4 4)}&\texttt{(double 4)}\\
%%           \texttt{(+ 3 3)}&\texttt{(double 3)}\\
%%           \multicolumn{2}{c}{$\cdots $}
%%       \end{tabular}};

    

%%     \end{tikzpicture}}

%%   \end{frame}

\begin{frame}{Abstraction Sleep: Growing the library via refactoring}
  \centering
    \Wider[0em]{\begin{tikzpicture}[every node/.style={inner sep=1,outer sep=0,rounded corners,thick, scale=0.7}]
  \footnotesize
  \node(p1)[draw,rounded corners,thick] at (-1,0) {
    \begin{tabular}{l}
      \texttt{(Y ($\lambda$ (r l) (if (nil? l) nil}\\
      \texttt{ (cons (+ (car l) (car l))}\\
      \phantom{\texttt{(cons }}\texttt{ (r (cdr l))))))}
    \end{tabular}
  };
  
  \node(p2)[draw] at ([xshift=4cm]p1.east) {
    \begin{tabular}{l}
      \texttt{(Y ($\lambda$ (r l) (if (nil? l) nil}\\
      \texttt{ (cons (- (car l) 1)}\\
      \phantom{\texttt{(cons }}\texttt{ (r (cdr l))))))}
    \end{tabular}
    
  };

    \node(t1)[draw] at ([yshift=1cm]p1.north) {\begin{tabular}{ll}
      \textbf{Task}:&\texttt{[1 2 3]$\to$[2 4 6]}\\
      &\texttt{[4 3 4]$\to$[8 6 8]}
  \end{tabular}};
  \draw [->] (t1.south)  --(p1.north) node[fill=white,midway] {Wake: program search};
  \node(t2)[draw] at ([yshift=1cm]p2.north) {\begin{tabular}{ll}
      \textbf{Task}:&\texttt{[1 2 3]$\to$[0 1 2]}\\
      &\texttt{[4 3 4]$\to$[3 2 3]}
  \end{tabular}};
  \draw [->] (t2.south)  --(p2.north) node[fill=white,midway] {Wake: program search};

  
  \pause
  \node(r1)[draw,inner sep=0,outer sep=0] at ([yshift=-2cm]p1.south) {
    \begin{tabular}{l}
      \texttt{(}\orange{\texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if (nil? l)}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{nil}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{(cons (f (car l))}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{ (r (cdr l)))))))}}\\
      \texttt{ ($\lambda$ (z) (+ z z)))}
    \end{tabular}
  };

  \node(r2)[draw] at ([yshift=-2cm]p2.south) {
    \begin{tabular}{l}
      \texttt{(}\orange{\texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if (nil? l)}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{nil}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{(cons (f (car l))}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{ (r (cdr l)))))))}}\\
      \texttt{ ($\lambda$ (z) (- z 1)))}
    \end{tabular}

  };

  \draw [->] (p1.south)  --(r1.north) node[fill=white,midway,align=center] {refactor\\($\mathbf{10^{14}}$ refactorings)};
  \draw [->] (p2.south)  --(r2.north) node[fill=white,midway,align=center] {refactor\\($\mathbf{10^{14}}$ refactorings)};



    \node(dummy) at ($(0,1) + (r1.north)!0.5!(r2.north)$) {};
    \node(dummy1) at (r1.west) {\phantom{t}};


    \draw[ultra thick] ($(r1.north west) + (-0.5,1)$) -- ($(r2.north east) + (0.5,1)$)
    -- ($(r2.north east) + (0.5,1) + (0,-5.75)$)
    -- ($(r1.north west) + (-0.5,1) + (0,-5.75)$)
    -- ($(r1.north west) + (-0.5,1)$);
    %  \node(sleepBox)[ultra thick, rounded corners=0, inner sep=25,outer sep=20, draw, fit= (dummy) (r1) (r2) (m) (dummy1) ] {};
    \node at ($(0.0,0.5) + (r1.north)!0.5!(r2.north)$) {{\normalsize\textbf{Sleep: Abstraction}}};

    \pause
    
    \node[draw](m) at ($(0,-2) + (r1.south)!0.5!(r2.south)$) {
      \begin{tabular}{lr}
        &\\
        \code{(}\fbox{\textsc{map}}\code{ ($\lambda$ (z) (+ z z)))}&
        \code{(}\fbox{\textsc{map}}\code{ ($\lambda$ (z) (- z 1)))}\\&\\
        \multicolumn{2}{l}{\fbox{\textsc{map}} = \orange{\texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if (nil? l) nil}}}\\
        \multicolumn{2}{l}{\phantom{\texttt{\emph{map}} = \texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if }}\orange{\texttt{(cons (f (car l))}}}\\
        \multicolumn{2}{l}{\phantom{\texttt{\emph{map}} = \texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if }}\orange{\texttt{(r (cdr l))))))}}}
      \end{tabular}      
    };
    \draw [->](r1.south)--($(-1.75,-0.3) + (m.north)$);
    \draw [->](r2.south)--($(1.75,-0.3) + (m.north)$);
    \node[fill=white] at ([yshift=0.4cm]m.north) {\textbf{Compress (MDL/Bayes objective)}};

    \end{tikzpicture}}

    \only<4>{
      \messageOverlay{these $\mathbf{10^{14}}$ refactorings are represented in an\\ exponentially more efficient refactoring data structure\\ using $\mathbf{10^{6}}$ nodes, calculated in under 5min\\
      PL ideas: version spaces [Lau 2001], egraphs [Tate 2009]}
      }
\end{frame}




\begin{frame}{DreamCoder Domains}
  \Wider[5em]{
    \only<1>{\includegraphics[width = \textwidth]{figures/manyDomainsLarger.png}}%{statement/taskbar2_expended.png}}
    \only<2>{\includegraphics[width = \textwidth]{figures/manyDomainsSelected.png}}%statement/taskbar2_selected.png}}
  }
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{LOGO Turtle Graphics}
  30 out of 160 tasks
  \includegraphics[width = \textwidth]{dc/logoTasks30.png}
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{LOGO Turtle Graphics -- learning an interpretable library}
  \Wider[5em]{
    \only<1>{\includegraphics[width = \textwidth]{dc/logo_kathy.png}}
    \only<2>{\includegraphics[width = \textwidth]{dc/logo_kathy_exploded1.png}}
    \only<3>{\includegraphics[width = \textwidth]{dc/logo_kathy_exploded2.png}}
    \only<4>{\includegraphics[width = \textwidth]{dc/logo_kathy_exploded3.png}}
    \only<5->{\includegraphics[width = \textwidth]{dc/logo_kathy.png}}
      
  }

  \only<6>{
  \messageOverlay{
    \begin{tabular}{rl}
    circle$(r)$
    &\raisebox{-.5\height}{\includegraphics[width = 0.3\textwidth]{dc/logo_primitives/circle_negative.png}}\\
    arc$(n,\ell,\theta)$
    &\raisebox{-.5\height}{\includegraphics[width = 0.3\textwidth]{../dreamcoder/figures/logo_primitives/arc/arc.png}}
    %% polygon$(n,\ell)$
    %% &\raisebox{-.5\height}{\includegraphics[width = 0.3\textwidth]{dc/logo_primitives/polygon_negative.png}}
  \end{tabular}
  }}
  \only<5>{
    \messageOverlay{\begin{tabular}{c}
    radial symmetry$(n,\text{body})$\\
    \includegraphics[width = 0.35\textwidth]{dc/rotationalmontage_negative.png}
  \end{tabular}}
  }
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{What does DreamCoder dream of? (before learning)}
%  \emph{before} learning:
  \Wider[5em]{
    \begin{center}
      \includegraphics[height=\textheight]{dc/dreams/beforeLearning36}
    \end{center}
  }
%  \myPaper{Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}  
  %  \includegraphics[height=3cm]{dc/dreams/cherry_picked/montageSeptember14}    
%    \end{tabular}}
    %% \only<2>{\begin{tabular}{lll}
    %%     before learning&&after learning\\
    %%     \includegraphics[width = 0.4\textwidth]{dc/dreams/appendixlogoinitial.png}&&
    %%     \includegraphics[width = 0.4\textwidth]{dc/dreams/appendixlogofinal.png}
    %%     \end{tabular}}
\end{frame}

\begin{frame}{What does DreamCoder dream of? (after learning)}
%  \emph{after} learning:
  \Wider[4em]{
    \begin{center}
      \includegraphics[height=\textheight]{figures/postDreams6}
    \end{center}
  }
%  \myPaper{Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}  

%    \end{tabular}}
    %% \only<2>{\begin{tabular}{lll}
    %%     before learning&&after learning\\
    %%     \includegraphics[width = 0.4\textwidth]{dc/dreams/appendixlogoinitial.png}&&
    %%     \includegraphics[width = 0.4\textwidth]{dc/dreams/appendixlogofinal.png}
    %%     \end{tabular}}
\end{frame}

\begin{frame}{Planning to build towers}
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  \Wider[5.5em]{
    \footnotesize
    \begin{tabular}{l}
      {example tasks (112 total)}\\
      \includegraphics[clip, trim = 0 0cm 0 2.9cm,width = 0.9\textwidth]{dc/tower_montage_21_negative.png}\\\\

    \end{tabular}
    \pause
    \begin{tabular}{l}
      {learned library routines ($\approx $ 20 total)}\\
      \begin{tabular}[t]{rlrl}
        arch$(h)$&%\begin{tabular}{l}
        \raisebox{-.1\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_towerArch.png}}&
        %\end{tabular}&
        pyramid$(h)$&
        \raisebox{-.1\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_pyramid.png}}
        \\
        wall$(w,h)$&
        \raisebox{-.3\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_bricks.png}}
        &%\\\\
        %% stairs$(h)$&\begin{tabular}{l}
        %%   \includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_staircase.png}
        %% \end{tabular}\\\\
        \phantom{bbb}bridge$(w,h)$&
        \raisebox{-.3\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_bridge.png}}
        %\\\\\\
      \end{tabular}\\\\

  \end{tabular}}

  %% \pause

  %% \messageOverlay{
  %%   \begin{tabular}{ll}
  %%         \textbf{dreams before learning}&\textbf{dreams after learning}\\
  %%         \begin{tabular}{c}
  %%           \includegraphics[clip,trim = 0 4.5cm 0 0cm,width = 0.4\textwidth]{dc/tower/dreams/cherry_montage_initial_20.png}
  %%         \end{tabular}\phantom{testing}&
  %%         \begin{tabular}{c}
  %%           \includegraphics[clip,trim = 0 4.5cm 0 0cm,width = 0.4\textwidth]{dc/tower/dreams/cherry_montage_final.png}
  %%           \end{tabular}
  %%         \\\\
  %%     \end{tabular}
  %% }
\end{frame}

\begin{frame}{Dreams before learning}
  \includegraphics[clip,trim = 0 4.5cm 0 0cm,width = \textwidth]{dc/tower/dreams/cherry_montage_initial_20.png}
%  \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{Dreams after learning}
  \includegraphics[clip,trim = 0 4.5cm 0 0cm,width = \textwidth]{dc/tower/dreams/cherry_montage_final.png}
%  \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}
\begin{comment}
\begin{frame}{Learning dynamics}
  \phantom{
  \small baselines: Exploration-Compression, EC [Dechter et al. 2013]
    \small \phantom{baselines: }neural program synthesis, RobustFill [Devlin et al. 2017]\phantom{otest}
    \small \phantom{baselines: }24 hours of brute-force enumeration
    }
  \begin{tabular}{lr}
    \begin{tabular}{l}
    \only<1>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl_stage1.png}}
    %    \only<2>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl_stage2.png}}
    \only<2>{\includegraphics[height = 2.29cm]{figures/tower_hits_ws_average_pretty_small_yl_ablationStage.png}}
%    \only<3>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl_stage3.png}}
    \only<3>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl.png}}
  \end{tabular}

    &

    \begin{tabular}{l}
      \only<2>{\includegraphics[width = 3cm]{figures/revisedLearningCurves/curveLegendTruncated.png}}
          \only<3>{\includegraphics[width = 3cm]{figures/revisedLearningCurves/curveLegend.png}}
  \end{tabular}
  \end{tabular}

  

  \visible<3>{
    \small baselines: Exploration-Compression, EC [Dechter et al. 2013]
    \small \phantom{baselines: }neural program synthesis, RobustFill [Devlin et al. 2017]\phantom{otest}
    \small \phantom{baselines: }24 hours of brute-force enumeration
    }


  %% }
  %% }
 % \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{Learning dynamics}
  \begin{tabular}{ll}
    \includegraphics[height = 2cm]{figures/revisedLearningCurves/text_hits_average_pretty_small_yl.png}
    %      \only<4->{\includegraphics[height = 2cm]{figures/revisedLearningCurves/text_hits_average_pretty_small_yl.png}}
    &
    \phantom{ttt}%
    \includegraphics[height = 2cm]{figures/revisedLearningCurves/logo_hits_average_pretty_small.png}\\
    \includegraphics[height = 2cm]{figures/revisedLearningCurves/tower_hits_average_pretty_small_yl.png}&
    \phantom{ttt}%
    \includegraphics[height = 2cm]{figures/revisedLearningCurves/rational_hits_average_pretty_small.png}\\
    \includegraphics[height = 2.29cm]{figures/revisedLearningCurves/list_hard_hits_ws_average_pretty_small_yl.png}
    &
    \phantom{tt.}%
    \includegraphics[height = 2.29cm]{figures/revisedLearningCurves/regex_marginal_test_unigram_gen_ws.png}
    %      \only<4->{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/regex_marginal_test_unigram_gen_ws.png}}%
    %    \includegraphics[height = 2.29cm]{figures/revisedLearningCurves/regex_marginal_test_unigram_gen_ws.png}%
    \phantom{tt}\includegraphics[width = 2.5cm]{figures/revisedLearningCurves/curveLegend.png}\hspace{-3cm}
  \end{tabular}

  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  %% }
  %% }

\end{frame}
\end{comment}

\begin{frame}{Learning dynamics}
  \phantom{
  \small baselines: Exploration-Compression, EC [Dechter et al. 2013]
    \small \phantom{baselines: }neural program synthesis, RobustFill [Devlin et al. 2017]\phantom{otest}
    \small \phantom{baselines: }24 hours of brute-force enumeration
    }
  \begin{tabular}{lr}
    \begin{tabular}{l}
    \only<1>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl_stage1.png}}
    %    \only<2>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl_stage2.png}}
    \only<2>{\includegraphics[height = 2.29cm]{figures/tower_hits_ws_average_pretty_small_yl_ablationStage.png}}
%    \only<3>{\includegraphics[height = 2.29cm]{figures/revisedLearningCurves/tower_hits_ws_average_pretty_small_yl_stage3.png}}
    \only<3>{\includegraphics[height = 2.29cm]{figures/memorizeMontage/tower_memorize_talk_hits_ws_average_pretty_small_yl.png}}
  \end{tabular}

    &

    \begin{tabular}{l}
      \only<2>{\includegraphics[width = 3cm]{figures/revisedLearningCurves/curveLegendTruncated.png}}
          \only<3>{\includegraphics[width = 3cm]{figures/memorizeMontage/curveLegend.png}}
  \end{tabular}
  \end{tabular}

  

  \visible<3>{
    \small baselines: memorize programs rather than refactor them [Cropper 2019]
    \small \phantom{baselines: }neural program synthesis, RobustFill [Devlin et al. 2017]\phantom{otest}
    \small \phantom{baselines: }24 hours of brute-force enumeration
    }


  %% }
  %% }
 % \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{Learning dynamics}
  \begin{tabular}{ll}
    \includegraphics[height = 2cm]{figures/memorizeMontage/text_talk_memorize_hits_average_pretty_small_yl.png}
    %      \only<4->{\includegraphics[height = 2cm]{figures/memorizeMontage/text_hits_average_pretty_small_yl.png}}
    &
    \phantom{ttt}%
    \includegraphics[height = 2cm]{figures/memorizeMontage/logo_memorize_talk_hits_average_pretty_small.png}\\
    \includegraphics[height = 2cm]{figures/memorizeMontage/tower_memorize_talk_hits_average_pretty_small_yl.png}&
    \phantom{ttt}%
    \includegraphics[height = 2cm]{figures/memorizeMontage/rational_memorize_talk_hits_average_pretty_small.png}\\
    \includegraphics[height = 2.29cm]{figures/memorizeMontage/list_talk_memorize_hard_hits_ws_average_pretty_small_yl.png}
    &
    \phantom{tt.}%
    \includegraphics[height = 2.29cm]{figures/memorizeMontage/regex_marginal_memorize_talk.png}
    %      \only<4->{\includegraphics[height = 2.29cm]{figures/memorizeMontage/regex_marginal_test_unigram_gen_ws.png}}%
    %    \includegraphics[height = 2.29cm]{figures/memorizeMontage/regex_marginal_test_unigram_gen_ws.png}%
    \phantom{tt}\includegraphics[width = 2.5cm]{figures/memorizeMontage/curveLegend.png}\hspace{-3cm}
  \end{tabular}

  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  %% }
  %% }

\end{frame}

\begin{frame}{Synergy between dreaming and library learning}
  \begin{tikzpicture}[scale=1.5]
    {
    \begin{scope}[shift = {(1,-1)}]
    \node[align = center](synthesis) at (6,4) {Problem-solving};
    \node[align = center](Library) at (3,1) {Library};
    \node[align = center](recognitionModel) at (9,1) {Recognition \\model};

    \visible<2->{
      \draw [->,thick] (synthesis.-120) to[out = -150,in = 60] node[below,rotate = 45,align = center]{{\footnotesize Trains}\\{\footnotesize (Abstraction)}} (Library.30);
    }
    \visible<3->{
%      \draw [->,thick] (synthesis.-60) to[out = -30,in = 120] node[below,rotate=-45,align = center]{{\footnotesize Trains}\\{\footnotesize (Dreaming)}} (recognitionModel.150);
      \draw [->,thick] (Library.east) to[out = -30,in = 210] node[above, align = center]{{\footnotesize Trains}\\{\footnotesize (Dreaming)}} (recognitionModel.west);    
    }


    \visible<4->{
      \draw [->,thick] (recognitionModel.150) to[in = -30,out = 120] node[below,rotate=-45,align = center]{{\footnotesize Makes tractable}\\{\footnotesize (Wake)}} (synthesis.-60);
    }

    %% \visible<5->{
    %%   \draw [->,thick,dashed] (recognitionModel.north) to[out = 90,in = 0] node[fill=backgroundBeige,inner sep=1pt,align = center]{{\footnotesize Trains}\\{\footnotesize (Dreaming)}} (synthesis.east);
    %%   \draw [->,thick,dashed] (Library.north) to[out = 90,in = 180] node[fill=backgroundBeige,inner sep=0pt,align = center]{\footnotesize{Inductive bias}\\\footnotesize{(Wake)}
    %%   } (synthesis.west);
    %% }

  \end{scope}}
    \end{tikzpicture}
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}

\begin{frame}{Evidence for dreaming bootstrapping better libraries}
    \begin{tabular}{rr}
      %        \multicolumn{1}{l}{\textbf{B}}\\
      \only<1>{\includegraphics[height = 0.3\textwidth]{figures/depthVersusAccuracy_revision_MEAN_blue.png}}
    \only<2->{\includegraphics[height = 0.3\textwidth]{figures/depthVersusAccuracy_revision_MEAN.png}}&
    \visible<3->{\includegraphics[height = 0.3\textwidth]{figures/depthVersusAccuracy_revision_SIZE.png}} \\\\
\multicolumn{2}{c}{    \visible<2->{\includegraphics[height = 1cm]{figures/revisedLearningCurves/scatterLegend.png}}}
    \end{tabular}
    Darker: Early in learning

    Brighter: Later in learning
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}



%% \begin{frame}{Library structure: Probabilistic generative modeling of text}
%%   \Wider[5em]{\includegraphics[width = \textwidth]{deepArray2.pdf}}
%% \end{frame}

\begin{frame}{}

  {\huge
    From learning libraries,\phantom{tttesttesttest} \phantom{Fr} to learning languages}

  \vspace{2cm}

  \Wider[4em]{
    \visible<3>{\Large 1950's Lisp $\to $  }\visible<2->{\Large modern functional programming $\to $ physics}
  }
\end{frame}

\begin{frame}{}
  \begin{center}
    \includegraphics[width = 0.8\textwidth]{figures/PhysicsFormulas}
   \end{center}
\end{frame}

\begin{frame}{Growing languages for vector algebra and physics}
  %\myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  \Wider[5em]{
    \only<1>{\includegraphics[width = \textwidth]{figures/physicsAnimation7}}
    \only<2>{\includegraphics[width = \textwidth]{figures/physicsAnimation6}}
    \only<3>{\includegraphics[width = \textwidth]{figures/physicsAnimation5}}
%    \only<4>{\includegraphics[width = \textwidth]{figures/physicsAnimation4}}
    \only<4>{\includegraphics[width = \textwidth]{figures/physicsAnimation3}}
    \only<5>{\includegraphics[width = \textwidth]{figures/physicsAnimation2}}
    \only<6>{\includegraphics[width = \textwidth]{figures/physicsAnimation1}}
  }
\end{frame}

\begin{frame}{Growing a language for recursive programming}
  % \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
  \Wider[5em]{\only<1>{\includegraphics[width = \textwidth]{figures/mcCarthyAnimation5}}
    \only<2>{\includegraphics[width = \textwidth]{figures/mcCarthyAnimation4}}
    \only<3>{\includegraphics[width = \textwidth]{figures/mcCarthyAnimation3}}
    \only<4->{\includegraphics[width = \textwidth]{figures/mcCarthyAnimation2}}
%    \only<5>{\includegraphics[width = \textwidth]{figures/mcCarthyAnimation1}}
  }

  \vspace{-0.5cm}
  
  \visible<6>{\textbf{\Large 1 year of compute. 5 days on 64 CPUs.}}
  
  \visible<5->{
    \begin{tabular}{cc}
      \begin{tabular}{c}
        \includegraphics[width = 2cm]{figures/origamiCrane}
        \end{tabular}&\normalsize Origami Programming: Jeremy Gibbons, 2003
    \end{tabular}
  }
\end{frame}

\begin{frame}{Lessons}

  Symbols aren't necessarily interpretable. Flexibly grow the language based on experience to make it more powerful \emph{and} more human understandable

  \vspace{1cm}

  Learning-from-scratch is possible in principle. Don't do it. But program induction makes it convenient to build in what we know how to build in, and then learn and adapt on top of that
\end{frame}

\begin{frame}{}
  \begin{center}
    \begin{tabular}{l}
      {\textcolor{black}{Program Induction and }\textcolor{gray}{perception}}\\
      \phantom{Program Induction and }{\textcolor{gray}{learning to learn}}\\
      \phantom{Program Induction and }{\textcolor{gray}{model discovery}}\\
      \phantom{Program Induction and }{\textcolor{black}{the future}}
      \end{tabular}
  \end{center}
\end{frame}

\begin{frame}{}
  This work:\\ a toolkit for program induction,\\addressing combinatorial program search via learning, integrating techniques for machine learning, AI, and programming languages %symbolic, probabilistic, and neural techniques
  

  \vspace{2cm}

  Where should we aim?
\end{frame}

%% \begin{frame}{What's in reach}
%%   \Wider[5em]{
%%     \begin{center}
%%       \begin{tabular}[t]{ccc}
%%         \closex{0.3}{
%%           \begin{tabular}{c}
%%             \only<2>{\textbf{Library learning+}}\only<1>{Library learning+}\only<3->{Library learning+}\\
%%             \only<2>{\textbf{Natural language}}\only<1>{Natural language}\only<3->{Natural language}\\
%%             \includegraphics[width = 3cm]{figures/semanticParsing}
%%           \end{tabular}
%%         }&

%%         \closex{0.3}{
%%           \begin{tabular}{c}
%%             \only<1-2>{Computer-Aided}\only<3>{\textbf{Computer-Aided}}\only<4->{Computer-Aided}\\
%%             \only<1-2>{Science}\only<3>{\textbf{Science}}\only<4->{Science}\\
%%             \includegraphics[width = 3cm]{figures/geneInteraction}
%%           \end{tabular}
%%         }&

%%         \closex{0.3}{
%%           \begin{tabular}{c}
%%             \only<1-3>{Synthesis for}\only<4>{\textbf{Synthesis for}}\only<5->{Synthesis for}\\
%%             \only<1-3>{software engineers}\only<4>{\textbf{software engineers}}\only<5->{software engineers}\\
%%             \includegraphics[width = 3cm]{figures/IDE}
%%           \end{tabular}
%%         }
        
        
%%       \end{tabular}

%%       \vspace{0.6cm}

%%       \begin{tabular}{cc}
%%         \closex{0.3}{
%%           \begin{tabular}{c}

%%             \only<1-4>{Theory for}\only<5>{\textbf{Theory for}}\only<6->{Theory for}\\
%%             \only<1-4>{program induction}\only<5>{\textbf{program induction}}\only<6->{program induction}\\
%%             \includegraphics[width = 3cm]{figures/formula}\\
%%             \includegraphics[width = 2cm]{figures/complexityTextbook} 
%%           \end{tabular}
%%         }

%%         &

%%         \closex{0.3}{
%%           \begin{tabular}{c}
%%             \only<1-5>{Modeling the}\only<6>{\textbf{Modeling the}}\\%\only<4-6>{Modeling the}\only<7>{\textbf{Modeling the}}\\
%%             \only<1-5>{physical world}\only<6>{\textbf{physical world}}\\%\only<4-6>{physical world}\only<7>{\textbf{physical world}}\\
%%             \includegraphics[width = 3cm]{figures/room}\\\phantom{t}
%%           \end{tabular}
%%         }
        
%%       \end{tabular}
%%     \end{center}
%% }
%% \end{frame}

%% \begin{frame}{Within reach: Modeling the physical world}
%%   \begin{tabular}{rcc}
%%     \begin{tabular}{c}
%%       hinge
%%     \end{tabular}&
%%     \begin{tabular}{c}
%%       \includegraphics[width = 3cm]{figures/hinge}
%%     \end{tabular}&
%%     \begin{tabular}{c}
%%       \includegraphics[width = 3cm]{figures/laptopHinge}
%%     \end{tabular}\\
%%     \vspace{1cm}
%%     \\
%%     \multicolumn{1}{c}{
%%       \begin{tabular}{c}
%%         gear
%%       \end{tabular}
%%     }&
%%     %empty
%%     &
%%     \begin{tabular}{c}
%%       doorknob
%%     \end{tabular}\\
%%     \begin{tabular}{c}
%%       \includegraphics[width = 3cm]{figures/gears}
%%     \end{tabular}&
%%     &
%%     \begin{tabular}{c}
%%       \includegraphics[width = 3cm]{figures/doorknob}
%%     \end{tabular}
%%   \end{tabular}
%% \end{frame}

%% \begin{frame}{Within reach: Modeling the physical world}
%%   \Wider[5em]{
%%     \begin{center}
%%       \input{vapor.tex}
%%     \end{center}
%%   }
%% \end{frame}



\begin{frame}{What we want for the future of machine learning}

  Strong generalization %%in many domains

  %% \vspace{1cm}

  %% Domain generality

  \vspace{1cm}

\pause  Bootstrapping, learning-to-learn, representation learning

  \vspace{1cm}

\pause  Discovering knowledge that humans can understand and build on

\end{frame}
\begin{comment}
  \renewcommand{\insertframenumber}{}
  \begin{frame}{What do we want from machine learning?}
    \Wider[4em]{
      \vspace*{-0.25cm}    \closex{0.1}{\closey{1pt}{\begin{tabular}{rccc}
            Strong generalization&
            \begin{tabular}{rcl}
              %% \begin{tabular}{c}
              %%   \includegraphics[width = 1.5cm]{TikZfigures/extrapolationDrawing1.png}
              %% \end{tabular}&$\to$&%
              %% \begin{tabular}{c}
              %%   \includegraphics[width = 1.5cm]{TikZfigures/extrapolationExtrapolation1.png}
              %% \end{tabular}\\
              \begin{tabular}{c}
                \includegraphics[width = 1.5cm]{TikZfigures/extrapolationDrawing2.png}
              \end{tabular}&$\to$&%
              \begin{tabular}{c}
                \includegraphics[width = 1.5cm]{TikZfigures/extrapolationExtrapolation2.png}
              \end{tabular}
            \end{tabular}&\phantom{test}&
            \begin{tabular}{c}
              \includegraphics[width = 1.75cm]{dc/dreams/cherry_picked/65_pretty.png}
            \end{tabular}
      \end{tabular}}}

      \visible<2->{

        %  \vspace{1cm}

        Bootstrapping, learning-to-learn, representation learning
        \closex{0.1}{\closey{1pt}{\begin{tabular}{l}
              \multicolumn{1}{c}{\begin{tabular}{llll}
                  \phantom{testtest}&
                  \begin{tabular}{c}
                    \includegraphics[width = 4cm]{figures/finalLearningCurveMontage}
                  \end{tabular}&\phantom{test}&\begin{tabular}{c}
                    \visible<3->{\includegraphics[width = 4cm]{../dreamcoder/figures/dpl/every/text6.pdf}}
                  \end{tabular}
              \end{tabular}}
            \end{tabular}
        }}
      }


      %  \vspace{1cm}

      \phantom{test}

      \visible<4->{
        \closex{0.1}{\closey{1pt}{\begin{tabular}{l}
              Discovering knowledge that humans can understand and build on\\
              \begin{tabular}{lll}
                \begin{tabular}{c}
                  \includegraphics[width = 0.15\textwidth]{figures/odden}
                \end{tabular}&
                \begin{tabular}{c}
                  \includegraphics[width = 0.15\textwidth]{figures/spe}
                \end{tabular}&
                \begin{tabular}{cc}
                  \begin{tabular}{c}
                    \includegraphics[width = 2cm]{figures/origamiCrane}
                  \end{tabular}&
                  \begin{tabular}{c}
                    \includegraphics[width = 6cm]{figures/mcCarthyAnimationFinalMontage}
                  \end{tabular}
                \end{tabular}
              \end{tabular}
            \end{tabular}
        }}
      }

    }
  \end{frame}
\end{comment}


\begin{frame}{A language of thought for \\the mental representation of geometric shapes}

  
  

  \centering\begin{tabular}{c}
    \only<1>{\includegraphics[width = 0.7\textwidth]{french_geometric}}
    \only<2>{\includegraphics[width = 0.55\textwidth]{french_geometric2}}
    \only<3>{\includegraphics[width = 0.5\textwidth]{french_geometric3}}
    
    \end{tabular}

\visible<3>{Program structure predicts:\\ human shape similarity judgments\\ human processing time}

\myPaper{Mathias Sable-Meyer, Ellis, Tenenbaum, Dehaene. 2022}

\end{frame}


\begin{frame}{}

  \Huge\centering

  \texttt{the end.}

  \end{frame}

\begin{frame}
  \only<1>{\includegraphics[width = \textwidth]{cycleGraphicalModel5}}
  \only<2>{\includegraphics[width = \textwidth]{cycleGraphicalModelRecognition}}
\end{frame}

\begin{frame}[t]{Neural recognition model guides search}
  \vspace{1.2cm}
  \begin{tikzpicture}
    \node(t) at (0,0) {task};
    \node(n) at ([xshift=2cm]task.east) {
      \NeuralNetwork{0.17}};
    \node(p) at ([xshift=2cm]n.east) {program};
    \draw[thick,->] (t.east) -- ([xshift=-0.4cm]n.west);
    \draw[thick,->] ([xshift=0.4cm]n.east) -- (p.west);

    %% \node(n1) at ([yshift=-2cm]t.south) {\phantom{.}};
    %% \node[anchor=north west,align=left](c1) at ([xshift=0.5cm,yshift=0.3cm]n1.east) {\phantom{is a \textbf{``bigram'' model over syntax trees}}\\\phantom{test}\\\phantom{test}}\\\phantom{test}};
  \end{tikzpicture}

\end{frame}
\begin{frame}[t]{Neural recognition model guides search}
  \vspace{1cm}
  \begin{tikzpicture}
    \node(t) at (0,0) {task};
    \node(n) at ([xshift=2cm]task.east) {
      \NeuralNetwork{0.17}};
    \node(d) at ([xshift=2cm]n.east) {distribution};
    \draw[thick,->] (t.east) -- ([xshift=-0.4cm]n.west);
    \draw[thick,->] ([xshift=0.4cm]n.east) -- (d.west);
    \node(p) at ([xshift=2cm]d.east) {program};
    \draw[squiggle, thick,->] (d.east) -- node[sloped,above]{{{sample}}} (p.west);

    \pause

    \node(n1) at ([yshift=-2cm]t.south) {\NeuralNetwork{0.17}};
    \node[anchor=north west,align=left](c1) at ([xshift=0.5cm,yshift=0.3cm]n1.east) {is a...\\\phantom{is a...}recurrent network (Devlin et al 2017)\\
      \phantom{is a...}unigram model (Menon et al 2013; Balog et al 2016)};
  \end{tikzpicture}
\end{frame}
\begin{frame}[t]{Neural recognition model guides search}
  \vspace{1cm}
  \begin{tikzpicture}
    \node(t) at (0,0) {task};
    \node(n) at ([xshift=2cm]task.east) {
      \NeuralNetwork{0.17}};
    \node[align=left](d) at ([xshift=2cm]n.east) {distribution};
    \node[anchor=north] at (d.south) {{\tiny P(child$\vert$parent,arg)}};
    \draw[thick,->] (t.east) -- ([xshift=-0.4cm]n.west);
    \draw[thick,->] ([xshift=0.4cm]n.east) -- (d.west);
    \node(p) at ([xshift=2cm]d.east) {program};
    \draw[squiggle, thick,->] (d.east) -- node[sloped,above]{{{sample}}} (p.west);

    \only<1>{
      \node(n1) at ([yshift=-2cm]t.south) {\NeuralNetwork{0.17}};
      \node[anchor=north west,align=left](c1) at ([xshift=0.5cm,yshift=0.3cm]n1.east) {is a \textbf{``bigram'' model over syntax trees}};
    }

    \only<2->{
%      \node(l)[draw] at (2,-1) {\texttt{$\lambda$ (a)}};
      \node(k)[draw] at (1.7,-1.3) {\texttt{+}};
      \only<3->{
      \node(o)[draw] at ([xshift=-50,yshift=-50]k.south) {\texttt{9}};
      \draw[->] (k.south)--node[sloped, above]{\tiny P($\cdot \vert$ \texttt{+},\text{arg}=\text{left})}(o.north);
      }
      \only<4->{
        \node(m)[draw] at ([xshift=50,yshift=-50]k.south) {\texttt{*}};
        \draw[->] (k.south)--node[sloped, above]{\tiny P($\cdot \vert$ \texttt{+},\text{arg}=\text{right})}(m.north);
      }
      \only<5->{
        \node(x1)[draw] at ([xshift=50,yshift=-50]m.south) {\texttt{2}};
        \node(x2)[draw] at ([xshift=-50,yshift=-50]m.south) {\texttt{8}};

        %      \draw[->] (l.south)-- node[fill=white,align=center,midway,inner sep=0,outer sep=0]{$Q_{\text{start},\texttt{+},1}(x)$}(k.north);
        

        \draw[->] (m.south)--node[sloped, above]{\tiny P($\cdot \vert$ \texttt{*},\text{arg}=\text{left})}(x1.north);
        \draw[->] (m.south)--node[sloped, above]{\tiny P($\cdot \vert$ \texttt{*},\text{arg}=\text{right})}(x2.north);
      }

      \only<6>{
        \node[draw,rounded corners,ultra thick,align=left,anchor=north west] at (4.6,-0.7) {Advantages:\\neural net runs once per task,\\\phantom{tt}so CPU bottlenecks instead of GPU};
      }
      \only<7>{
        \node[draw,rounded corners,ultra thick,align=left,anchor=north west] at (4.6,-0.7) {Advantages:\\neural net runs once per task,\\\phantom{tt}so CPU bottlenecks instead of GPU\\learns to break syntactic symmetries:\\\phantom{tt}P(1$\vert$\texttt{*},\text{arg}=\text{left})=0.0\\\phantom{tttt}``do not multiply by one''};
        }
    }
  \end{tikzpicture}
\end{frame}


%% \begin{frame}{Scaling to long programs}
%%   Branching factor: $ > 400$ actions

%%   Successfully synthesizes 40-action programs

%%   \vspace{1cm}
  
%%   \Wider[5em]{
%% \centering
%%   \setlength{\tabcolsep}{2pt}
%%   \renewcommand{\arraystretch}{1}
%%   \footnotesize

%% \begin{tabular}{|lll|}
%% \cline{1-3}% \cline{5-6}
%% \multicolumn{3}{|c|}{Spec:}\\% &  & \multicolumn{3}{c|}{Spec:} \\
%% 6/12/2003 & $\to$ & date: 12 mo: 6 year: 2003\\% &  & Dr Mary Jane  Lennon & $\to$ & Lennon, Mary Jane (Dr) \\
%% 3/16/1997 & $\to$ & date: 16 mo: 3 year: 1997 \\%&  & Mrs Isaac  McCormick & $\to$ & McCormick, Isaac (Mrs) \\ \cline{1-3} \cline{5-7} 
%% \cline{1-3}\multicolumn{3}{|c|}{Held out test instance:}\\% &  & \multicolumn{3}{c|}{Held out test instance:} \\
%% 12/8/2019 & $\to$ & date: 8 mo: 12 year: 2019\\% &  & Dr James Watson & $\to$ & Watson, James (Dr) \\ \cline{1-3} \cline{5-7} 
%% \cline{1-3}\multicolumn{3}{|c|}{Results:}\\% &  & \multicolumn{3}{c|}{Results:} \\
%% \textbf{Ours} & $\to$ & \textbf{date: 8 mo: 12 year: 2019}\\% &  & \textbf{} & $\to$ & \textbf{Watson, James (Dr)} \\
%% %% Rollout & $\to$ & date: 8 mo: 1282019\\% &  &  & $\to$ & Watson, James \\
%% %% Beam w/value & $\to$ & date: 8 mo: 12 year:2019\\% &  &  & $\to$ & Watson, JamesDr \\
%% %% Beam & $\to$ & date: 8 mo: 12 year:\\% &  &  & $\to$ & Watson, James ( \\
%% RobustFill & $\to$ & date:12/8/2019\\% &  &  & $\to$ & Dr James  Watson \\ \cline{1-3} \cline{5-7}
%% \cline{1-3}
%% \end{tabular}
%%   \setlength{\tabcolsep}{6pt}
%%   \renewcommand{\arraystretch}{1}
%% }
%% \end{frame}



%% \begin{frame}{Vision}


%%    \underline{More human-like machine intelligence}\\%Flexibly adapting to new problem domains:
%%    \begin{itemize}
%%    \item    Acquiring a domain-specific representation (DSL)
%%      \item Learning  to use that representation (recognition model)
%%    \end{itemize}
%%    DreamCoder: an algorithm for jointly realizing these goals

   



%%    \hspace{-1cm}\includegraphics[width = 12cm]{ecFigures/finale.png}

%%    \pause

%%    \Huge \centering \textbf{The End.}
%%   \end{frame}
\newcommand{\image}[2]{\includegraphics[#1]{../dreamcoder/figures/dpl/every/#2.pdf}}
\begin{frame}{Library structure: Text Editing}
  \Wider[5em]{
    DreamCoder learns libraries for FlashFill-style text editing  [Gulwani 2012]

    \vspace{0.5cm}

    \begin{tabular}{cc}
      \image{height=2.4cm}{text3}&
      \image{height=2.4cm}{text6}\\
      \image{height=2.4cm}{text5}&
      \image{height=2.4cm}{text4}
    \end{tabular}
  }
  \myPaper{\small Ellis, Wong, Nye, ..., Solar-Lezama, Tenenbaum. PLDI 2021.}
\end{frame}
\begin{frame}{Library structure: Generating Text}
  Libraries for probabilistic generative models over text:\\data from crawling web for CSV files

  
  \Wider[5em]{\begin{center}
    
    \begin{tabular}{cc}
      \image{height=3cm}{regex3}&
      \image{height=3.5cm}{regex1}\\
      \image{height=3.5cm}{regex2}&
      \image{height=3cm}{regex4}
    \end{tabular}
    \end{center}
  }
\end{frame}

\begin{frame}{150 random dreams before learning}
  \includegraphics[width = \textwidth]{../dreamcoder/figures/dreams/appendixlogoinitial.png}
\end{frame}
\begin{frame}{150 random dreams after learning}
  \includegraphics[width = \textwidth]{../dreamcoder/figures/dreams/appendixlogofinal.png}
\end{frame}
\end{document}
