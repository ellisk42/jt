\documentclass{beamer}
%\setbeamersize{text margin left=10pt,text margin right=10pt}
\usetheme{metropolis}
\usepackage{listings}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{verbatim}
%\usepackage{tipa}
\usepackage{tikz}
\usetikzlibrary{fit}
\usepackage{color}
\usepackage{booktabs}
\usepackage{tipa}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage[absolute,overlay]{textpos}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{decorations.pathmorphing}
\tikzset{squiggle/.style={decorate, decoration={snake,amplitude=.4mm}}}
\usepackage{xcolor}
\definecolor{pop1}{HTML}{1F78b4}
\definecolor{pop2}{HTML}{164C13}
\definecolor{pop3}{HTML}{d95F02}
\definecolor{orange}{HTML}{d95F02}
\definecolor{teal}{HTML}{1b9e77}
\newcommand{\pop}[1]{\textcolor{pop1}{#1}}
\newcommand{\popp}[1]{\textcolor{pop2}{#1}}
\newcommand{\tree}[1]{\textcolor{pop3}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}
\newcommand{\teal}[1]{\textcolor{teal}{#1}}
\newcommand{\code}[1]{{\footnotesize\texttt{#1}}}
\newcommand{\greenCode}[1]{{\footnotesize\popp{\code{#1}}}}
\newcommand{\blueCode}[1]{{\footnotesize\pop{\code{#1}}}}
\definecolor{backgroundGreen}{HTML}{23373b}
\lstset{escapeinside={<@}{@>}}
\usepackage{pgf}  

\newcommand{\Expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\indicator}{\mathds{1}} %{{\rm I\kern-.3em E}}
\newcommand{\expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\probability}{\mathds{P}} %{{\rm I\kern-.3em P}}
\DeclareMathOperator*{\argmin}{arg\,min} % thin space, limits underneath in displays
\DeclareMathOperator*{\argmax}{arg\,max} % thin space, limits underneath in displays

\usepackage[absolute,overlay]{textpos}

\newcommand{\nextForm}[1]{\rotatebox[origin=c]{270}{$_{\curvearrowright}$}$_{#1}$}
 
\usepackage{amsfonts}
\usepackage{tabularx}
%\usepackage{color}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{trees}
\usetikzlibrary{fit}
\usetikzlibrary{calc}
\usetikzlibrary{bayesnet}
\usepackage[absolute,overlay]{textpos}
\usepackage{stmaryrd}
\newcommand{\sem}[1]{\llbracket #1\rrbracket}
\newcommand{\tuple}[1]{\ensuremath{\left \langle #1\right \rangle}}
\newcommand{\messageOverlay}[1]{
      \tikz[overlay,remember picture]
      \node[align=left,fill=backgroundGreen,text=white] at (current page.center){#1};
}
\usepackage{booktabs}
\usepackage{tipa}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage[absolute,overlay]{textpos}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations.markings}

\newcommand\Wider[2][3em]{%
\makebox[\linewidth][c]{%
  \begin{minipage}{\dimexpr\textwidth+#1\relax}
  \raggedright#2
  \end{minipage}%
  }%
}

\newcommand{\denotation}[1]{{\llbracket #1 \rrbracket}}

\usepackage[utf8]{inputenc}
\newcommand{\reduce}{\longrightarrow}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont

\usepackage{fancyvrb}

\usepackage[most]{tcolorbox}
\definecolor{block-gray}{gray}{0.10}
\newtcolorbox{mycode}{colback=block-gray,grow to right by=0mm,grow to left
by=0mm, boxrule=0pt,boxsep=0pt,breakable,fontupper=\color{white}}

%% Program ::=
%%   (if Bool List
%%     (append RecursiveList
%%             RecursiveList
%%             RecursiveList))
%% RecursiveList ::= List
%%          | (recurse List)

            

\usepackage{arydshln}

\newcommand{\Expect}{\mathds{E}} %{{\rm I\kern-.3em E}}
\newcommand{\Probability}{\mathds{P}} %{{\rm I\kern-.3em P}}

\DeclareMathOperator*{\argmax}{arg\,max}
%Information to be included in the title page:
\title{Program Induction:\\Bridging AI and program synthesis,\\ by learning to write code that writes code}
\author{Kevin Ellis}
\institute{MIT} 
\date{2020}
  
 
\begin{document}
 
\frame{\titlepage}

\begin{frame}[fragile]{Perception, Learning-to-Learn, Synthesizing models}

  Theme \#1: high-level scene understanding, pixels$\to $programs %going from high-dimensional percepts to symbolic program representations

  \only<1>{\includegraphics[width = \textwidth]{graphicsTeaser.pdf}}
  \only<2->{{\centering\includegraphics[width = 0.6\textwidth]{assets/we_are_cool_4.png}}}
  
  \only<2->{Theme \#2: Learning to synthesize programs}
  \only<2>{\includegraphics[width = 0.9\textwidth]{statement/taskbar2.png}}
  \only<3->{\includegraphics[width = 1\textwidth]{statement/taskbar_short.png}}
  \only<3->{Theme \#3: Synthesizing human-understandable models}
  \only<3>{\includegraphics[width = \textwidth]{phonology/qualitativeSupplement2.pdf}}
\end{frame}

\begin{frame}{High-level, abstract visual abilities}

  %% \begin{textblock*}{1cm}(1cm,0.25\textwidth)
  %%   \begin{exampleblock}{}
  %%     test
  %%     \end{exampleblock}
  %% \end{textblock*}


  \begin{tabular}{ccc}
    \includegraphics[width = 0.3\textwidth]{figures/textile}&
    \includegraphics[width = 0.3\textwidth]{figures/mce}&
    \visible<2->{\includegraphics[width = 0.3\textwidth]{figures/rnn}}\\
    \visible<2->{\includegraphics[width = 0.3\textwidth]{figures/graphicalModel}}&
    \visible<3->{\includegraphics[width = 0.3\textwidth]{figures/dinner}}&
    \visible<3->{\includegraphics[width = 0.3\textwidth]{figures/aqueduct}}\\
    \visible<4->{\hspace*{-1cm}\includegraphics[width = 0.4\textwidth]{figures/bg.png}}&
    \visible<5->{\includegraphics[width = 0.3\textwidth]{figures/CAD_laptop}}&
    \visible<6->{\includegraphics[width = 0.3\textwidth]{figures/fractal_tree}}&
  \end{tabular}

  \visible<7->{
    \messageOverlay{why?\\\phantom{te}impute missing objects, extrapolate percepts,\\\phantom{te}learn visual concepts (`arch', `spiral', HMM),\\\phantom{te}assist graphic design, assist 3D modeling\\how?\\\phantom{te}Bayesian inference of graphics program conditioned on image,\\\phantom{te}+program synthesis\\\phantom{te}+learning}
  }
\end{frame}

\begin{frame}[fragile]{Learning to infer graphics programs from hand-drawn images}
\hspace*{-1cm}\begin{tikzpicture}
    \node(picture1) at (0,-1) {\includegraphics[height = 2.2cm]{TikZfigures/expert-31.png}};
    \node[draw,right=1cm of picture1] (c1) {
        \begin{lstlisting}[basicstyle = \small\ttfamily]
for (0 <= i < 3)
 rectangle(3*i,-2*i+4,
           3*i+2,6)
 for (0 <= j < i + 1)
  circle(3*i+1,-2*j+5)
        \end{lstlisting}
      };
    
    \draw[very thick,->] (picture1.east)  -- (c1.west);

    \node(l1)[anchor=south] at ([yshift=0.75cm,xshift=2.5cm]picture1.north) {model infers program from drawing};
\end{tikzpicture}

    \vskip0pt plus 1filll
    \hspace*{-0.75cm}\underline{Ellis}, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.
\end{frame}

\begin{frame}[fragile]{Learning to infer graphics programs from hand-drawn images}
  
\hspace*{-1cm}\begin{tikzpicture}
    \node(picture1) at (0,-1) {\includegraphics[height = 2.2cm]{TikZfigures/expert-31.png}};
    \node[draw,right=1cm of picture1] (c1) {
        \begin{lstlisting}[basicstyle = \small\ttfamily]
for (0 <= i < 3 <@\textcolor{red}{\textbf{+ 1}}@>)
 rectangle(3*i,-2*i+4,
           3*i+2,6)
 for (0 <= j < i + 1)
  circle(3*i+1,-2*j+5)
        \end{lstlisting}
      };
    
    \draw[very thick,->] (picture1.east)  -- (c1.west);    

    \node(e)[anchor=west] at ([xshift=1cm]c1.east) {\includegraphics[width = 2.2cm]{TikZfigures/31-extrapolated.png}};
    
    \draw[very thick,->] (c1.east)  -- (e.west);
    \node(l1)[anchor=south] at ([yshift=0.75cm,xshift=2.5cm]picture1.north) {model infers program from drawing};
    \node[anchor=north west] at ([yshift=0.09cm]l1.south west) {\textbf{zero-shot generalization / extrapolation}};
\end{tikzpicture}

\visible<2>{

  \phantom{te}
  
  \hspace*{-1cm}\includegraphics[width = 1.2\textwidth]{TikZfigures/extrapolationMatrix1.png}
}

%    \vskip0pt plus 1filll
    \hspace*{-0.75cm}\underline{Ellis}, Ritchie, Solar-Lezama, Tenenbaum. NeurIPS 2018.
\end{frame}

\begin{frame}[fragile]{How to infer graphics programs from hand-drawn images}

\hspace*{-1cm}\begin{tikzpicture}[scale=0.9]
  \node[ thick,anchor = west,inner sep=0pt,label={[yshift = 0.3cm]{\small \begin{tabular}{c}
          \textbf{Image}\\
          \textbf{(Observed)}
  \end{tabular}}}](observation) at (0,0) {\includegraphics[width = 1.5cm]{TikZfigures/expert-39-trimmed.png}};
    \node[ultra thick,anchor = west,inner sep=0pt](traceSource) at (3.7,0.5){    \begin{lstlisting}[basicstyle = \scriptsize\ttfamily]
line, line,
rectangle,
line, ...
\end{lstlisting}};
    \node[ultra thick,anchor = west,inner sep=0pt](traceImage) at (4.15,-0.6) {
      \includegraphics[width = 0.9cm]{TikZfigures/39-parse.png}}; 
    \node(trace)[draw,thin,fit = (traceImage) (traceSource), label = above:{{\small \begin{tabular}{c}
            \textbf{Spec/Drawing Commands}\\
            \textbf{(Latent)}
    \end{tabular}}}] {};
    
    \node[draw, thick,anchor = west,inner sep=2pt,label=above:{\small \begin{tabular}{c}
          \textbf{Program}\\
          \textbf{(Latent)}
    \end{tabular}}](program) at (7.7,0) {
      \begin{lstlisting}[basicstyle = \scriptsize\ttfamily]
for (j < 3)
for (i < 3)
if (...)
 line(...)
 line(...)
rectangle(...)
    \end{lstlisting}};

%    \node[ultra thick,anchor = west,inner sep=0pt,label=below:{\small Similarity}](similarity) at (11.3,0) {\includegraphics[width = 1cm]{TikZfigures/expert-38-trim.png}};


    
    \draw[->, ultra thick] ([yshift=10]trace.west) to[out = 150,in = 30] node[midway,yshift = 6]{{\small render}} ([xshift=5,yshift=10]observation.east); % -- node[fill = white,rotate = -90] {{\small Rendering}}
    \draw[->, ultra thick] ([yshift=10]program.west) to[out = 150,in = 30] node[midway,yshift = 6] {{\small exec}} ([yshift=10]trace.east);
    
    \pause
    \draw[->, very thick, red] ([yshift = -15,xshift=3]observation.east) to[out = -30,in = -150] node[midway,yshift = -19,xshift=0]{{\small \begin{tabular}{l}
          learning+ \\SMC
    \end{tabular}}} ([yshift = -15]trace.west);

    \draw[->, very thick, red] ([yshift = -15,xshift=0]trace.east) to[out = -30,in = -150] node[midway,yshift = -23,xshift=14]{{\small \begin{tabular}{l}
          learning+ \\program synthesis
    \end{tabular}}} ([yshift = -15]program.west);
%    \draw[->, thick, red, very thick] ([xshift = 10]trace.south) to[out = -10,in = -170] node[midway,yshift = -6]{{\small Learning + Program synthesis}} ([xshift = 10]program.south);
%    \draw[->, thick, red] (program.east) to[out = 80,in = 180] (errors.west);
%    \draw[->, thick] (program.east) to[out = 40,in = -230] (similarity.west);


    \draw[decoration = {brace,mirror,raise = 5pt},decorate,thick]
    ([yshift = -40,xshift = -130]trace.south) -- node[below = 6pt] {{\small  Image$\to$Spec}} ([yshift = -40,xshift = -5]trace.south);
    \draw[decoration = {brace,mirror,raise = 5pt},decorate,thick]
    ([xshift = 5,yshift = -40]trace.south) -- node[below = 6pt] {{\small Spec$\to$Program}} ([xshift = 170,yshift = -40]trace.south);

    \pause
    \node[ultra thick,anchor = west,inner sep=0pt,label=below:{\small extrapolation}](extrapolate) at (11.8,0.9) {\includegraphics[width = 1.3cm]{TikZfigures/39-extrapolated.png}};
    \draw[->, thick, red, very thick] (program.east) to[out = 60,in = 180] (extrapolate.west);
    \node[ultra thick,anchor = west,text width = 2.3cm,inner sep=0pt](errors) at (11.1,-1) {\small error correction};
    
    \draw[decoration = {brace,mirror,raise = 5pt},decorate,thick]
([xshift = 180,yshift = -40]trace.south) -- node[below = 6pt] {{\small Applications}} ([xshift = 255,yshift = -40]trace.south);
  \end{tikzpicture}
\end{frame}

\begin{frame}{Parsing images into specs (\LaTeX~TikZ commands)}

{\footnotesize  Neurally Guided Procedural Modeling (Ritchie et al 2016) + \\Attend, Infer, Repeat (Eslami et al 2016)}
  \vspace{-0.5cm}
  \begin{center}
    \begin{tabular}{c}
\raisebox{-.5\height}{    \includegraphics[width = 0.8\textwidth]{../TikZpaper/architecture.pdf}            }
      \end{tabular}

  \end{center}

    \newcommand{\noisySize}{0.12\textwidth}
    \visible<2->{
\hspace{0.1\textwidth}      \begin{minipage}[t]{\noisySize}
        \centering\includegraphics[width = \textwidth]{TikZfigures/expert-60-reduced.png}\\
                                  {\small     hand drawing}
      \end{minipage}\hspace{0.05\textwidth}%
      \begin{minipage}[t]{\noisySize}
        \centering\includegraphics[width = \textwidth]{TikZfigures/60-1-reduced.png}\\
                                  {\small noisy \\rerender}
      \end{minipage}}%
    %% \visible<3->{\begin{minipage}{0.35\textwidth}
    %%     \begin{flushright}
    %%       \textbf{Learned distance metric}\\
    %%       \small    Serves as likelihood surrogate
    %%       \begin{align*}
    %%         \displaystyle\qquad    -\log L_{\text{learned}}(\text{render}&(S_1)|\text{render}(S_2))\approx\\& |S_1 - S_2| + |S_2 - S_1|
    %%       \end{align*}
    %%       $S_1$: noisy render\\
    %%       $S_2$: nonnoisy render
    %%     \end{flushright}
    %% \end{minipage}}%
    \hspace{0.2\textwidth}%
    \only<3>{\begin{minipage}[c]{0.3\textwidth}
\vspace{0.4cm}      \includegraphics[width = 0.8\textwidth]{TikZfigures/evaluationPhase1}
    \end{minipage}}
        \only<4>{\begin{minipage}[c]{0.3\textwidth}
\vspace{0.4cm}      \includegraphics[width = 0.8\textwidth]{TikZfigures/evaluationPhase2}
    \end{minipage}}
\end{frame}


%% \begin{frame}{Human program induction everywhere}
%% \begin{tikzpicture}
%%   \node(Lisp) at (0,0) {\includegraphics[width = 5cm]{ecFigures/1975.png}};
%%   \visible<2->{
%%     \node(colorless) at (6,0) {\includegraphics[width = 5cm]{ecFigures/colorless.png}};
%%     \node at ([yshift=-2cm]colorless.south) {\includegraphics[width = 4cm]{ecFigures/child.jpg}};
%%   }
%%   \visible<3->{
%%     \node(aqueduct) at ([yshift=-1cm,xshift=0cm]Lisp.south) {\includegraphics[width = 5cm]{ecFigures/aqueduct.jpg}};
%%     \node(arch) at ([xshift=1cm,yshift=0cm]aqueduct.south) {\includegraphics[width = 1.5cm]{ecFigures/arch.jpg}};
%%   }
%%   \visible<4->{
%%     \node at ([yshift=-1cm,xshift=-2cm]aqueduct.south) {\includegraphics[width = 2cm]{ecFigures/tapestry.jpg}};
%%     \node(wiringDiagram) at ([yshift=-1cm,xshift=1.6cm]aqueduct.south) {\includegraphics[width = 5cm]{ecFigures/wiringDiagram.jpg}};
%%   }
%%   %% \visible<5->{
%%   %%   \node at ([xshift=2cm,yshift=1cm]wiringDiagram.east) {\includegraphics[width = 5cm]{tree.jpg}};
%%   %%   }
%%   \end{tikzpicture}

%% \end{frame}

%% %% \begin{frame}{Engineering the language of thought}
%% %%  \begin{tikzpicture}
%% %%     \node () {\includegraphics[width = 15.6cm]{theory.png}};
%% %%     \node at (-5,-4) {  Ullman et al 2012};
%% %%     \end{tikzpicture}
%% %% \end{frame}

%% \begin{frame}{Human program induction everywhere}
%%   \begin{tikzpicture}
%%     \node at(0,0) {\includegraphics[width = 8cm]{characters.png}};
%%     \node at(-3,2) {\includegraphics[width = 8cm]{Brendan.jpg}};

%%     \node at (-5,-4) {  Lake et al 2015};
%%     \end{tikzpicture}
%% \end{frame}


\begin{frame}{Top-down influences on perception}
  \begin{tabular}{ccc}
    \small{drawing\phantom{tttttttttttttttt}}&\small{bottom-up neural net}&\small{w/ top-down program bias}\\
    \multicolumn{3}{c}{\includegraphics[width = \textwidth]{TikZfigures/programSuccess16_statement.png}}\\
    \multicolumn{3}{c}{\only<3>{\includegraphics[width = \textwidth]{TikZfigures/programSuccess71_statement.png}}}
    %        \multicolumn{3}{c}{\includegraphics[width = \textwidth]{TikZfigures/programSuccess97.png}}
  \end{tabular}

  \only<2>{
    \begin{align*}      
      &\hat{S}(I) = \argmax_{S\in \mathcal{F}(I)} \probability(I | \text{render}(S))\times \probability_{\beta} [ \text{program}(S)] \\
      %% \end{equation}
      %% \begin{equation}
      &  \beta^* = \argmax_{\beta} \expect \left[ \log \frac{\probability_{\beta} [\text{program}(S)]\times \probability(I|\text{render}(S))}{\sum_{S'\in \mathcal{F}(I)} \probability_{\beta} [\text{program}(S')]\times \probability(I|\text{render}(S'))} \right]
    \end{align*}
  }
\end{frame}

\begin{frame}{Example programs}
 \includegraphics[width = \textwidth]{../TikZpaper/exampleProgramsSpotlight.pdf}
  \pause
  \messageOverlay{Learning played a role...\\
    but much of this system is specific to 2-D graphics\\\\
  Goal: a general algorithm for learning to synthesize programs}
\end{frame}

\begin{frame}{Growing domain-specific knowledge}
  
  %  \Large
  Goal: acquire domain-specific knowledge needed to induce a class of programs


  
  \vspace{1cm}

  \begin{itemize}
  \item Library of concepts (declarative knowledge; domain specific language; generative model over programs)
    \item Inference strategy (procedural knowledge; synthesis algorithm)
  \end{itemize}
  \only<2>{
  \begin{tikzpicture}
    \node(problem) at (0,0) {\includegraphics[width = 2cm]{figures/cubic.png}};
    \node(synthesizer)[draw,align=center] at ([xshift=3cm]problem.east) {Learned \\program inducer};
    \draw[->] (problem.east) -- (synthesizer.west);
    \node(program)[draw, align=center] at ([xshift=3cm]synthesizer.east) {program:\\$f(x) = 0.3x^3+$\\$1.1x^2-2x+0.6$};
    \draw[->] (synthesizer.east) -- (program.west);
  \end{tikzpicture}
  
    \vspace{0.2cm}Concepts: $x^3$, $\alpha x + \beta$, etc\\Inference strategy: neurosymbolic search for programs}
  \renewcommand\code\texttt
    \only<3>{
  \begin{tikzpicture}
    \node(problem) at (0,0) {\includegraphics[width = 2cm]{figures/radialCircle.png}};
    \node(synthesizer)[draw,align=center] at ([xshift=3cm]problem.east) {Learned \\program inducer};
    \draw[->] (problem.east) -- (synthesizer.west);
    \node(program)[draw, align=center] at ([xshift=3cm]synthesizer.east) {program:\\\code{(radial-symmetry 5}\\\code{ (circle 3))}};
    \draw[->] (synthesizer.east) -- (program.west);
  \end{tikzpicture}
  
  \vspace{0.2cm}Concepts: \code{circle}, \code{radial-symmetry}, etc\\Inference strategy: neurosymbolic search for programs
    }
\end{frame}

\begin{frame}{Library learning}
  \centering
  
  \only<1>{  \includegraphics[width = \textwidth]{dc/small_list_dsl}}
  \only<2->{  \includegraphics[width = 0.7\textwidth]{dc/small_list_dsl}}


  
  \only<2>{\includegraphics[width = 0.7\textwidth]{dc/small_list_solution}}
  \only<3>{\includegraphics[width = 0.7\textwidth]{dc/entire_sort_solution}}
  
\end{frame}

\begin{frame}{DreamCoder}
  \begin{itemize}
  \item   \textbf{Wake:} Solve problems by writing programs
  \item \textbf{Sleep:} Improve DSL and neural recognition model:
    \begin{itemize}
    \item \textbf{Abstraction sleep:} Improve library
      \item \textbf{Dream sleep:} Improve neural inference model
    \end{itemize}
  \item   Combines ideas from Wake-Sleep \& Exploration-Compression % \& Program analysis
  \end{itemize}
\Wider[5.4em]{
  \begin{tikzpicture}
    \visible<2->{
      \node(Lisp) at (-3,0) {\includegraphics[width = 0.8\textwidth]{statement/taskbar2.png}};
    }
    \node at (2.5,1.3) {  \includegraphics[width = 4cm]{ecFigures/sleepingChild.jpg}};
    \end{tikzpicture}}


\end{frame}
\begin{frame}[t]{Library learning as Bayesian inference}
  %  \includegraphics[width = 11cm]{ecFigures/animation/EC.eps}
\centering  \begin{tikzpicture}[scale=1.3,line width=0.5mm]

  \node[latent,scale=1] at (3.5,3) (dx){Lib};
  \node[latent,scale=1] at ([yshift=-1.5cm]dx) (zp){prog};
  \node[obs,scale=1] at ([yshift=-2cm]zp) (xp) {data};
  \node[latent,scale=1] at ([xshift=2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=2cm]xp) (xp1) {data};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
  %\draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};
  % HACK : "invisible" arrow to phantom and push to the left and align with next
  % slide
  \draw [->,red,opacity=0.0001] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
  
  \node[latent,scale=1] at ([xshift=-2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=-2cm]xp) (xp1) {data};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
%  \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};


%  \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
 % \node at (nn) {\NeuralNetwork{0.5}};
  \draw [->] (dx.south) -- (zp.north);
  \draw [->] (zp.south) -- (xp.north);


  %\node[shift={+(0,-1.7)}] at (nn) { $Q$  };

  \end{tikzpicture}
  

\vspace{0.5cm}
  
[Dechter et al., 2013]  [Liang et al, 2010]; [Lake et al, 2015]

%\textbf{Dechter et al.}: Exploration-Compression. Inspiration for DreamCoder.

  %% \vfill
  %% Gray: Observed.\\
  %% White: Latent.\\
  %% Boxed (plate): Repeated.\\
  
\end{frame}
\newcommand{\NeuralNetwork}[1]{    \begin{tikzpicture}[x=2.5cm,y=1.25cm,transform canvas={scale=#1,shift={+(-1,2.5)}}]
      \tikzstyle{neuron}=[circle,fill=blue!50,minimum size=20pt]
      \fill[fill=white] (-0.25,-0.5) rectangle (2.25,-4.5);
      \node[rectangle] at (1,1) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (I-\name) at (0,-\y) {};
      \foreach \name / \y in {1,...,3}
          \node[neuron] (H-\name) at (1,-\y-0.5) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (O-\name) at (2,-\y) {};
      \foreach \source in {1,...,4}
          \foreach \dest in {1,...,3}
              \draw [-latex] (I-\source) -- (H-\dest);
      \foreach \source in {1,...,3}
          \foreach \dest in {1,...,4}
              \draw [-latex] (H-\source) -- (O-\dest);
    \end{tikzpicture}}
\begin{frame}[t]{Library learning as \alert{amortized} Bayesian inference}
\centering  \begin{tikzpicture}[scale=1.3,line width=0.5mm]

  \node[latent,scale=1] at (3.5,3) (dx){Lib};
  \node[latent,scale=1] at ([yshift=-1.5cm]dx) (zp){prog};
  \node[obs,scale=1] at ([yshift=-2cm]zp) (xp) {data};
  \node[latent,scale=1] at ([xshift=2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=2cm]xp) (xp1) {data};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
  \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};
  
  \node[latent,scale=1] at ([xshift=-2cm]zp) (zp1){prog};
  \node[obs,scale=1] at ([xshift=-2cm]xp) (xp1) {data};
  \draw [->] (zp1.south) -- (xp1.north);
  \draw [->] (dx.south) -- (zp1.north);
  \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%  \node at (nn) {\NeuralNetwork{0.5}};


  \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
  \node at (nn) {\NeuralNetwork{0.25}};
  \draw [->] (dx.south) -- (zp.north);
  \draw [->] (zp.south) -- (xp.north);


  %\node[shift={+(0,-1.7)}] at (nn) { $Q$  };

\end{tikzpicture}



amortized inference +\\ better program representation (Lisp) + \\library learning via program analysis + \\
new neural inference network for program synthesis

\end{frame}
\newcommand{\NeuralNetwork}[1]{    \begin{tikzpicture}[x=2.5cm,y=1.25cm,transform canvas={scale=#1,shift={+(-1,2.5)}}]
      \tikzstyle{neuron}=[circle,fill=blue!50,minimum size=20pt]
      \fill[fill=teal!5!white] (-0.25,-0.5) rectangle (2.25,-4.5);
      \node[rectangle] at (1,1) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (I-\name) at (0,-\y) {};
      \foreach \name / \y in {1,...,3}
          \node[neuron] (H-\name) at (1,-\y-0.5) {};
      \foreach \name / \y in {1,...,4}
          \node[neuron] (O-\name) at (2,-\y) {};
      \foreach \source in {1,...,4}
          \foreach \dest in {1,...,3}
              \draw [-latex] (I-\source) -- (H-\dest);
      \foreach \source in {1,...,3}
          \foreach \dest in {1,...,4}
              \draw [-latex] (H-\source) -- (O-\dest);
    \end{tikzpicture}}
\newcommand{\spiral}[2]{
  \draw[ultra thick,->] ([shift={#1}]-30:#2) arc [radius = #2, start angle = -30, end angle = 90];
  \draw[ultra thick,->] ([shift={#1}]-30:#2) arc [radius = #2, start angle = -30, end angle = 95];

  
      \draw[ultra thick,->] ([shift={#1}]90:#2) arc [radius = #2, start angle = 90, end angle = 210];
      \draw[ultra thick,->] ([shift={#1}]90:#2) arc [radius = #2, start angle = 90, end angle = 205];
      
      \draw[ultra thick,->] ([shift={#1}]210:#2) arc [radius = #2, start angle = 210, end angle = 340];
      \draw[ultra thick,->] ([shift={#1}]210:#2) arc [radius = #2, start angle = 210, end angle = 335];
}
\newcommand{\legend}{
  \begin{tikzpicture}
    \node at (0,0) (uses){is};
    \draw[->,red] ([xshift=-0.6cm]uses.west)  -- (uses.west);
    \node at ([xshift=0.4cm]uses.east) {\NeuralNetwork{0.15}};
    \draw[thin] (-1,-0.4) rectangle (1.2,0.4);
  \end{tikzpicture}
}

\begin{frame}{}
  \centering
  \only<1>{\includegraphics[width = 0.3\textwidth]{cycleGraphicalModel1}}
  \only<2>{\includegraphics[width = \textwidth]{cycleGraphicalModel2}}
  \only<3>{\includegraphics[width = \textwidth]{cycleGraphicalModel3}}
  \only<4>{\includegraphics[width = \textwidth]{cycleGraphicalModel4}}
  \only<5>{\includegraphics[width = \textwidth]{cycleGraphicalModel5}}
\end{frame}

%% \begin{frame}{DreamCoder's sleep cycles}
%% \tiny\begin{tikzpicture}[scale=0.55,line width=0.25mm]
%%     \draw[fill=teal!5!white] (-1.25,1.25) -- (13.25,1.25) -- (13.25,-4) -- (-1.25,-4) -- (-1.25,1.25);
%%     \node at (5.5,1.5) {\textsc{\textbf{Wake}}};

    
%%     \begin{scope}[shift={(0.5,0.5)}]
%%       \node[align=center] at (0,-0.5) (d){
%%         \begin{tabular}{l}
%%           \multicolumn{1}{c}{\textbf{Library}}\\
%%         \texttt{$f_1($x$)=$(+ x 1)}\\
%%         \texttt{$f_2($z$)=$(fold cons}\\
%%         \phantom{\texttt{$f_2($z$)$}}\texttt{(cons z nil))}\\
%%  $\cdots\cdots\cdots$
%%                 \end{tabular}};
%%       \node[align=center] at ([yshift = -2cm]d) (t){\textbf{Task}\\
%%                     \texttt{[7\, 2\, 3]}$\to$\texttt{[4 3 8]}         \\
%%             \texttt{[3\, 8]}$\to$\texttt{[9 4]}\\
%%             \texttt{[4\, 3\, 2]}$\to$\texttt{[3 4 5]} };

%%       \node at ([xshift = 1.25cm]t.east) (nn){\NeuralNetwork{0.1}};
%%       \node[align = center, text width = 1cm] at ([yshift = 0.7cm,xshift=0cm]nn.north) {\baselineskip=0pt  Recog. model\par};
%%       \draw [red,-{>[scale=0.2]}] (t.east) -- ([xshift = -0.5cm]nn.west);

%%       \node[draw,rounded corners, align=center, inner sep = 5] at ([xshift = 4.2cm,yshift = 1cm]t.east) (s){Neurally-Guided\\ Enumerative Search};

%%       \draw [red,->] ([xshift = 0.5cm]nn.east) -- ([yshift = -0.25cm]s.west);
%%       \draw [->,rounded corners,] (d.east) -- ([yshift = 2cm]nn.center) -- ([yshift = 0.25cm]s.west);

%%       \node[align=left] at ([xshift=3cm]s.east) (f) {\textbf{Programs for task:}\\
%%             \texttt{(map $f_1$ (fold $f_2$ nil x))}\\
%%          $\cdots\cdots\cdots$};
%%       \draw [->  ] (s.east) -- (f.west);

%%       \draw [->  ,rounded corners] (t.south) -- ([yshift = -0.5cm]t.south) -- ([yshift = -0.5cm] s.south |- t.south) -- (s.south);
%%     \end{scope}
    
%%     \begin{scope}[shift={(9.4,-3.5)},scale=0.6,line width=0.05mm]
%%       \node[obs,scale=0.7] at (3.5,3) (dx){Library};
%%       \node[latent,scale=0.7] at ([yshift=-1.7cm,xshift=0cm]dx) (zp){prog};
%%       \node[obs,scale=0.7] at ([yshift=-1.45cm]zp) (xp) {task};
%%       \node[latent,scale=0.7] at ([xshift=1.5cm]zp) (zp1){prog};
%%       \node[obs,scale=0.7] at ([xshift=1.5cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%       \node[latent,scale=0.7] at ([xshift=-1.5cm]zp) (zp1){prog};
%%       \node[obs,scale=0.7] at ([xshift=-1.5cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->] (dx.south) -- (zp.north);
%%       \draw [->] (zp.south) -- (xp.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%       \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
%%     \end{scope}


%%     \node at (0,-4.75) {\textbf{\textsc{Sleep: Abstraction}}};
%%     \draw[fill=teal!5!white] (-3,-5) -- (3,-5) -- (3,-10) -- (5.5,-10) -- (5.5,-13) -- (-3,-13) -- (-3,-5);
%%     \node at (12,-4.75) {\textbf{\textsc{Sleep: Dreaming}}};
%%     \draw[fill=teal!5!white] (15,-5) -- (9,-5) -- (9,-10) -- (6.5,-10) -- (6.5,-13) -- (15,-13) -- (15,-5);

%%     \begin{scope}[shift={(9.5,-4.5)}]
%%       \node(dreaming) at (1,-1) {\underline{Fantasies}};
%%       \node[anchor=center] at ([yshift=-0.5cm]dreaming.south) (d){\textbf{Library}};
%%       \node at ([yshift=-1.75cm]d.south) (p1){program};
%%       \draw[squiggle,-> ] (d.south) -- node[sloped,above]{{ sample}} (p1.north);

%%       \node(replay) at ([xshift=2cm]dreaming.east) {\underline{Replays}};
%%       \node[anchor=center,align=center] at ([yshift=-0.5cm]replay.south) (d){\textbf{progs. for task}};
%%       \node at ([yshift=-1.75cm]d.south) (p1){program};
%%       \draw[squiggle,-> ] (d.south) -- node[sloped,above]{ sample} (p1.north);

%%       \node(p1) at (1.5,-6) {program};      
%%       \node at ([xshift = 2.0cm]p1.east) (t1){ task};
%%       \draw [-> ] (p1.east) -- node[above]{ run} (t1.west);
%%       \node(n) at ([yshift=-1.2cm,xshift=1.25cm]p1.south) {
%%         \NeuralNetwork{0.17}};
%%       \draw [->,red] (t1.south) to[out = -90,in = 0]  ([xshift=0.4cm]n.east);
%%       \draw [dashed] (p1.south) to[out=-120,in=180] node[above,fill=teal!5!white]{\color{black}Loss} ([xshift=-0.4cm]n.west);


%%       \node at ($(-0.25,0.5) + (p1.north)!0.5!(t1.north)$) {\underline{Train recognition model}};

%%       %% \node at ([xshift = 1.5cm]p1.east) (t1){ task};
%%       %% \draw [-> ] (p1.east) -- node[above]{ run} (t1.west);
%%       %% \node(n) at ([yshift=-1.2cm,xshift=0.4cm]p1.south) {
%%       %%   \NeuralNetwork{0.17}};
%%       %% \draw [->,red] (t1.south) to[out = -90,in = 0]  ([xshift=0.4cm]n.east);
%%       %% \draw [dashed] (p1.south) to[out=-120,in=180] node[above,fill=white]{\color{black}Loss} ([xshift=-0.4cm]n.west);

%%       \begin{scope}[shift={(-3.8,-8)},scale=0.6,line width=0.05mm]
%%         \node[obs,scale=0.4] at (3.5,3) (dx){L};
%%         \node[obs,scale=0.4] at ([yshift=-1.7cm,xshift=0cm]dx) (zp){p};
%%         \node[obs,scale=0.4] at ([yshift=-1.45cm]zp) (xp) {t};
%%         \node[obs,scale=0.4] at ([xshift=1.5cm]zp) (zp1){p};
%%         \node[obs,scale=0.4] at ([xshift=1.5cm]xp) (xp1) {t};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%         \node[obs,scale=0.4] at ([xshift=-1.5cm]zp) (zp1){p};
%%         \node[obs,scale=0.4] at ([xshift=-1.5cm]xp) (xp1) {t};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \draw [->] (dx.south) -- (zp.north);
%%         \draw [->] (zp.south) -- (xp.north);
%%         \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
%%         \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
%%       \end{scope}


%%       \end{scope}

%%     % memory consolidation
%%     \begin{scope}[shift={(-2,-4.5)}]

%%       %% defined routines for creating fragmented syntax trees
%%       \newcommand{\syntaxOne}[1]{
%%         \begin{tikzpicture}[scale=#1,line width=0.35mm]          
%%           \node(l1) at (0,0) {};
%%           \node[color=pop3](p1) at (-1,-1) {\texttt{+}};
%%           \node[color=pop3](n1) at (0.7,-0.9) {\texttt{1}};
%%           \node(x1) at (0,-1) {\texttt{1}};
%%           \draw[color=pop3] (l1.south) -- (p1.north);
%%           \draw[color=pop3] (l1.south) -- (n1.north);
%%           \draw[color=pop3] (-0.5,-0.45) -- (x1.north);

%%           \node(t) at (-0.5,0.5) {};
%%           \draw (l1.south) -- (t.south);
%%           \node(c) at (-1.5,-0.2) {\texttt{cons}};
%%           \draw (t.south) -- (c.north);
%%         \end{tikzpicture}
%%       }
%%       \newcommand{\syntaxTo}[1]{
%%         \begin{tikzpicture}[scale=#1,line width=0.35mm]          
%%             \node(l1) at (0,0) {};
%%             \node[color=pop3](p1) at (-1,-1) {\texttt{+}};
%%             \node[color=pop3](n1) at (0.7,-0.9) {\texttt{1}};
%%             \draw[color=pop3] (l1.south) -- (p1.north);
%%             \draw[color=pop3] (l1.south) -- (n1.north);
%%             \draw[color=pop3] (-0.5,-0.45) -- (0,-1);
%%             \node(c) at (-0.5,-1.5) {\texttt{car}};
%%             \node(z) at (0.5,-1.5) {\texttt{z}};
%%             \draw (0,-1) -- (c.north);
%%             \draw (0,-1) -- (z.north);
%%         \end{tikzpicture}
%%       }

%%       \node[align=center,anchor=center] at (0.4,-1.2) (f1){\textbf{ progs. for task 1}:\\\texttt{(+ (car z) 1)}};
%%       \node[align=center] at ([xshift = 1.75cm]f1.east) (f2){\textbf{  progs. for task 2}:\\\texttt{(cons (+ 1 1))}};
%%       \node(s1) at ([yshift=-0.5cm]f1.south) {\syntaxOne{0.5}};
%%       \node(s2) at ([yshift=-0.5cm]f2.south) {\syntaxTo{0.5}};
%%       \node(c)[align=center,rectangle, rounded corners, draw, minimum width = 1cm, minimum height = 0.5cm, anchor = north] at ($(s1.south)!0.5!(s2.south) + (0,-1)$) {Refactoring Algorithm};
%%       \draw [-> ] (s1.south) -- (s1.south|-c.north);
%%       \draw [-> ] (s2.south) -- (s2.south|-c.north);

      
%%       \node(d) at ([yshift = -1.8cm]c.south) {
%%         \begin{tikzpicture}[scale=0.5,line width=0.5mm]
%%           \node[align=center] at (0,0) {\textbf{new Library} w/ \texttt{(+ x 1)}:};
%%           \begin{scope}[shift={(0.6,-0.5)}]
%%             \node[pop3](p1) at (-1,-1) {\texttt{+}};
%%             \node[pop3](n1) at (0.6,-0.9) {\texttt{1}};
%%             \node[pop3](a) at (0,-1) {\texttt{ }};
%%             \draw[pop3] (0,0) -- (p1.north);
%%             \draw[pop3] (0,0) -- (n1.north);
%%             \draw[pop3] (-0.3,-0.3) -- (a.north);
%%           \end{scope}
%%       \end{tikzpicture}};
%%       \draw [-> ] (c.south) -- (d.north);



%%       \begin{scope}[shift={(4,-8)},scale=0.6,line width=0.05mm]
%%         \node[latent,scale=0.7] at (3.5,3) (dx){Library};
%%         \node[obs,scale=0.7] at ([yshift=-1.7cm,xshift=0cm]dx) (zp){prog};
%%         \node[obs,scale=0.7] at ([yshift=-1.45cm]zp) (xp) {task};
%%         \node[obs,scale=0.7] at ([xshift=1.5cm]zp) (zp1){prog};
%%         \node[obs,scale=0.7] at ([xshift=1.5cm]xp) (xp1) {task};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \node[obs,scale=0.7] at ([xshift=-1.5cm]zp) (zp1){prog};
%%         \node[obs,scale=0.7] at ([xshift=-1.5cm]xp) (xp1) {task};
%%         \draw [->] (zp1.south) -- (xp1.north);
%%         \draw [->] (dx.south) -- (zp1.north);
%%         \draw [->] (dx.south) -- (zp.north);
%%         \draw [->] (zp.south) -- (xp.north);
%%       \end{scope}


%%       \end{scope}


    
%%     %% center spiral
%%     \begin{scope}[shift={(3.25,-7.9)},scale=0.8]    
%%       \spiral{(3.5,1)}{3.5}
%%       \node[latent,scale=1] at (3.5,3) (dx){Library};
%%       \node[latent,scale=1] at ([yshift=-2cm,xshift=0cm]dx) (zp){prog};
%%       \node[obs,scale=1] at ([yshift=-1.45cm]zp) (xp) {task};
%%       \node[latent,scale=1] at ([xshift=2cm]zp) (zp1){prog};
%%       \node[obs,scale=1] at ([xshift=2cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);
      
%%       \node[latent,scale=1] at ([xshift=-2cm]zp) (zp1){prog};
%%       \node[obs,scale=1] at ([xshift=-2cm]xp) (xp1) {task};
%%       \draw [->] (zp1.south) -- (xp1.north);
%%       \draw [->] (dx.south) -- (zp1.north);
%%       \draw [->,red] (xp1.east) to[out = 30,in = -30] node(nn){} (zp1.east);


%%       \draw [->,red] (xp.east) to[out = 30,in = -30] node(nn){} (zp.east);
%%       \draw [->] (dx.south) -- (zp.north);
%%       \draw [->] (zp.south) -- (xp.north);

%%       \node at ([yshift=-0.6cm]xp.south) {\legend};

%%     \end{scope}    
%%   \end{tikzpicture}  

%% \end{frame}

\begin{frame}{Abstraction Sleep: Growing the library via refactoring}
  \centering
    \Wider[0em]{\begin{tikzpicture}[every node/.style={inner sep=1,outer sep=0,rounded corners,thick, scale=0.7}]
  \footnotesize
  \node(p1)[draw,rounded corners,thick] at (-1,0) {
    \begin{tabular}{l}
      \texttt{(Y ($\lambda$ (r l) (if (nil? l) nil}\\
      \texttt{ (cons (+ (car l) (car l))}\\
      \phantom{\texttt{(cons }}\texttt{ (r (cdr l))))))}
    \end{tabular}
  };
  
  \node(p2)[draw] at ([xshift=4cm]p1.east) {
    \begin{tabular}{l}
      \texttt{(Y ($\lambda$ (r l) (if (nil? l) nil}\\
      \texttt{ (cons (- (car l) 1)}\\
      \phantom{\texttt{(cons }}\texttt{ (r (cdr l))))))}
    \end{tabular}
    
  };

    \node(t1)[draw] at ([yshift=1cm]p1.north) {\begin{tabular}{ll}
      \textbf{Task}:&\texttt{(1 2 3)$\to$(2 4 6)}\\
      &\texttt{(4 3 4)$\to$(8 6 8)}
  \end{tabular}};
  \draw [->] (t1.south)  --(p1.north) node[fill=white,midway] {Wake: program search};
  \node(t2)[draw] at ([yshift=1cm]p2.north) {\begin{tabular}{ll}
      \textbf{Task}:&\texttt{(1 2 3)$\to$(0 1 2)}\\
      &\texttt{(4 3 4)$\to$(3 2 3)}
  \end{tabular}};
  \draw [->] (t2.south)  --(p2.north) node[fill=white,midway] {Wake: program search};

  
  \pause
  \node(r1)[draw,inner sep=0,outer sep=0] at ([yshift=-2cm]p1.south) {
    \begin{tabular}{l}
      \texttt{(}\orange{\texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if (nil? l)}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{nil}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{(cons (f (car l))}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{ (r (cdr l)))))))}}\\
      \texttt{ ($\lambda$ (z) (+ z z)))}
    \end{tabular}
  };

  \node(r2)[draw] at ([yshift=-2cm]p2.south) {
    \begin{tabular}{l}
      \texttt{(}\orange{\texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if (nil? l)}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{nil}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{(cons (f (car l))}}\\
      \phantom{(($\lambda$ (f) (Y ($\lambda$ (r l)}\orange{\texttt{ (r (cdr l)))))))}}\\
      \texttt{ ($\lambda$ (z) (- z 1)))}
    \end{tabular}

  };

  \draw [->] (p1.south)  --(r1.north) node[fill=white,midway,align=center] {refactor\\($10^{14}$ refactorings)};
  \draw [->] (p2.south)  --(r2.north) node[fill=white,midway,align=center] {refactor\\($10^{14}$ refactorings)};



    \node(dummy) at ($(0,1) + (r1.north)!0.5!(r2.north)$) {};
    \node(dummy1) at (r1.west) {\phantom{t}};


    \draw[ultra thick] ($(r1.north west) + (-0.5,1)$) -- ($(r2.north east) + (0.5,1)$)
    -- ($(r2.north east) + (0.5,1) + (0,-5.75)$)
    -- ($(r1.north west) + (-0.5,1) + (0,-5.75)$)
    -- ($(r1.north west) + (-0.5,1)$);
    %  \node(sleepBox)[ultra thick, rounded corners=0, inner sep=25,outer sep=20, draw, fit= (dummy) (r1) (r2) (m) (dummy1) ] {};
    \node at ($(0.0,0.5) + (r1.north)!0.5!(r2.north)$) {{\normalsize\textbf{Sleep: Abstraction}}};

    \pause
    
    \node[draw](m) at ($(0,-2) + (r1.south)!0.5!(r2.south)$) {
      \begin{tabular}{lr}
        &\\
        \code{(}\fbox{\textsc{map}}\code{ ($\lambda$ (z) (+ z z)))}&
        \code{(}\fbox{\textsc{map}}\code{ ($\lambda$ (z) (- z 1)))}\\&\\
        \multicolumn{2}{l}{\fbox{\textsc{map}} = \orange{\texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if (nil? l) nil}}}\\
        \multicolumn{2}{l}{\phantom{\texttt{\emph{map}} = \texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if }}\orange{\texttt{(cons (f (car l))}}}\\
        \multicolumn{2}{l}{\phantom{\texttt{\emph{map}} = \texttt{($\lambda$ (f) (Y ($\lambda$ (r l) (if }}\orange{\texttt{(r (cdr l))))))}}}
      \end{tabular}      
    };
    \draw [->](r1.south)--($(-1.75,-0.3) + (m.north)$);
    \draw [->](r2.south)--($(1.75,-0.3) + (m.north)$);
    \node[fill=white] at ([yshift=0.4cm]m.north) {\textbf{Compress (MDL/Bayes objective)}};

    \end{tikzpicture}}
\end{frame}

\begin{frame}{Version space algebra for refactoring}
  \begin{tabular}{lr}
    \begin{tabular}{l}
      Expr\phantom{$\vert$}$\to $ var\\
      \phantom{Exprtt}$\vert$ $\lambda $var.Expr\\
      \phantom{Exprtt}$\vert$ (Expr Expr)\\
      \phantom{Exprtt}$\vert$ primitive\\
      \phantom{VStt$\vert$ VS$\uplus$VS}    \\
      \phantom{VStt$\vert$ $\Lambda$}    \\
      \phantom{VStt$\vert$ $\varnothing$    }

    \end{tabular}&
    \visible<2->{\begin{tabular}{lr}
      VS\phantom{$\vert$}$\to $ var\\
      \phantom{VStt}$\vert$ $\lambda $var.VS\\
      \phantom{VStt}$\vert$ (VS VS)\\
      \phantom{VStt}$\vert$ primitive    \\
      \phantom{VStt}$\vert$ VS$\uplus$VS&\emph{nondeterministic choice}    \\
      \phantom{VStt}$\vert$ $\Lambda$&\emph{choose any expression}    \\
      \phantom{VStt}$\vert$ $\varnothing$    &\emph{choose no expression}
    \end{tabular}}
  \end{tabular}

  
  \visible<3>{what version spaces mean:\begin{align*}
      \denotation{\text{var}}& = \left\{\text{var} \right\}&
      \denotation{v_1 \uplus v_2}& = \left\{e : v\in \left\{v_1,v_2 \right\},\;e\in \denotation{v} \right\}\\
      \denotation{\lambda x. v}& = \left\{\lambda x. e : e\in \denotation{v} \right\}&    
      \denotation{(v_1\; v_2)}& = \left\{(e_1\;e_2) : e_1\in \denotation{v_1},\;e_2\in \denotation{v_2} \right\}\\
      \denotation{\varnothing}& = \varnothing&
      \denotation{\Lambda}& = \Lambda
  \end{align*}}

\end{frame}

\begin{frame}{Using version spaces}
  \begin{tabular}{lr}
    \multicolumn{2}{l}{VS\phantom{$\vert$}$\to $ var\phantom{t}$\vert$ $\lambda $var.VS\phantom{t}$\vert$ (VS VS)\phantom{t}$\vert$ primitive}    \\
    \phantom{VStt}$\vert$ VS$\uplus$VS&\emph{nondeterministic choice}    \\
    \phantom{VStt}$\vert$ $\Lambda$&\emph{choose any expression}    \\
    \phantom{VStt}$\vert$ $\varnothing$    &\emph{choose no expression}
  \end{tabular}

  \vfill
  
\only<2>{exploit the fact that $e\in \denotation{v}$ can be efficiently computed:  
  \begin{align*}
  \textsc{refactor}(v|\text{Lib}) &= \begin{cases}
    e\text{, if $e\in \text{Lib}$ and $e\in \denotation{v}$}\\
    \textsc{refactor}'(v|\text{Lib})\text{, otherwise.}
  \end{cases}
\end{align*}
\begin{align*}
  \textsc{refactor}'(v|\text{Lib})& = v\text{, if $v$ is a primitive or variable}\\
  \textsc{refactor}'(\lambda x.b|\text{Lib}) &= \lambda x. \textsc{refactor}(b|\text{Lib})\\
  \textsc{refactor}'(v_1\;v_2|\text{Lib}) &= (\textsc{refactor}(v_1|\text{Lib})\phantom{t}\textsc{refactor}(v_2|\text{Lib}))\\
%  \textsc{refactor}'(v_1 \uplus v_2|\text{Lib}) &= \argmin_{e\in \left\{\textsc{refactor}(v|\text{Lib})\;:\;v\in V \right\}}\text{size}(e|\text{Lib})
  \end{align*}}

\only<3->{%% invert $\beta$-reduction via new $I\beta$ operator
  \centering

  \begin{tikzpicture}[every node/.style={inner sep=1,outer sep=0,rounded corners,thick}]
    \node[draw, rounded corners](u1) at (0,0) {union, $\uplus$};
    \node[draw, rounded corners](u2) at ($(0,-1) + (u1.south)$) {\code{(}$\uplus$\code{ 1)}}; \draw (u1.south) -- (u2.north);
    \node[draw, rounded corners](u21) at ($(-1.3,-1) + (u2.south)$) {\code{(($\lambda$ (x) (x 1)) +)}}; \draw ([xshift=-0.2cm]u2.south) -- (u21.north);
    \node[draw, rounded corners](u22) at ($(2.3,-1) + (u2.south)$) {\code{(($\lambda$ (x) (+ x)) 1)}};  \draw ([xshift=-0.2cm]u2.south) -- (u22.north);

    \node[draw, rounded corners](u11) at ($(-1.75,-1) + (u1.south)$) {\code{(+ 1 1)}}; \draw (u1.south) -- (u11.north);
    \node[draw, rounded corners](u12) at ($(2.75,-1) + (u1.south)$) {\code{(($\lambda$ (x) (x 1 1)) +)}}; \draw (u1.south) -- (u12.north);

    \node(vs) at ($(u21.west)!0.5!(u12.east) + (0,-1.25)$) {$\underbrace{\hspace{8cm}}_{\text{\normalsize Subset of version space}}$};

    \node[anchor=north](p) at ($(0,2.5) + (u1)$) {\normalsize Program: \texttt{(+ 1 1)}};
    \draw[ultra thick,->] ($(0,-0.1) + (p.south)$) --node[sloped, above, inner sep=5]{$I\beta$} ($(0,0.1) + (u1.north)$);  
\end{tikzpicture}
}

\only<4>{
  \messageOverlay{\textbf{completeness:} $I\beta$ gets all the refactorings\\
    let $v_2 = I\beta(v_1)$ and $e_1\in \denotation{v_1}$. for any $e_2\reduce e_1$ then $e_2\in \denotation{v_2}$\\\\
    \textbf{consistency:} $I\beta$ only gets valid refactorings\\
    let $v_2 = I\beta(v_1)$ and $e_2\in \denotation{v_2}$. then there is a $e_1\in \denotation{v_1}$ where $e_2\reduce e_1$
  }
  }

\end{frame}






%% \begin{frame}{DreamCoder --- Sleep-R (\textbf{Experience Replay})}
%%   \only<1>{
%%     \includegraphics[width=11cm]{ecFigures/teachDC/.inkslides-sleep-r-1/slide-4.pdf}
%%   }
%% \end{frame}
%% \begin{frame}{DreamCoder --- Sleep-R (\textbf{Dreaming})}
%%   \only<1>{
%%     \includegraphics[width=11cm]{ecFigures/teachDC/.inkslides-sleep-r-2/slide-4.pdf}
%%   }
%% \end{frame}
 

%% \begin{frame}{List functions --- \small{Created \& investigated by Lucas
%%   Morales}}


%%   \vspace{1cm}
  
%%   \begin{figure}[b]\centering
%% \vspace{-0.5cm}  \begin{tabular}{lll}
%%     \toprule
%%     Name & Input & Output \\\midrule
%%     repeat-3 & [7\, 0] & [7\, 0\, 7\, 0\, 7\, 0] \\
%%     drop-3 & [0\, 3\, 8\, 6\, 4] & [6\, 4] \\
%%     rotate-2 & [8\, 14\, 1\, 9] & [1\, 9\, 8\, 14] \\
%%     count-head-in-tail & [1\, 2\, 1\, 1\, 3] & 2 \\
%%     keep-div-5 & [5\, 9\, 14\, 6\, 3\, 0] & [5\, 0] \\
%%     product & [7\, 1\, 6\, 2] & 84 \\
%%     \bottomrule
%%   \end{tabular}
%%   %\captionof{table}{Some tasks in our list function domain.}\label{listExamples}\vspace{-0.5cm}
%% \end{figure}

%%   Discovers 38 concepts, including `filter'. %With different tasks will also learn `map', `fold', `unfold', etc. starting with 1950's Lispthe
  
%% \begin{picture}(50,70) \put(250,0){\hbox{\includegraphics[width = 3cm]{ecFigures/Lucas}}} \end{picture} 
%% \end{frame}


%% \begin{frame}{Text editing}
%%   In the style of FlashFill (Gulwani 2012)

%%   \centering  \includegraphics[width = 5cm]{textColumn.png}

%% \vspace{-0.5cm}  SyGuS problems: solves 3\% before learning, vs 75\% after learning. Best prior work: 80\%

%% \end{frame}$

%% \begin{frame}{List functions \& Text editing: Learning curves on hold out tasks}

%%   \begin{center}
%%     \includegraphics[width = 5cm]{ecFigures/listLearningCurve.eps}
%% \hfill    \includegraphics[width = 5cm]{ecFigures/textLearningCurve.eps} 
%%     \end{center}

%% Learning curves for DreamCoder both with (\orange{in orange}) and without
%%     (\teal{in teal}) the recognition model. Solid lines: \% holdout testing tasks solved w/ 10m timeout. Dashed lines: Average solve time, averaged only over tasks that are solved.


%% \end{frame}


%% \begin{frame}{Learned text processing DSL}
%%   \only<1>{  \includegraphics[width = \textwidth]{ecFigures/textPrimitives.pdf}}
%%   \only<2>{  \includegraphics[width = \textwidth]{ecFigures/textPrimitives.png}}

%% \end{frame}

%% \begin{frame}{Learning the fundamentals of programming}
%%   \includegraphics[width = \textwidth]{ecFigures/McCarthy.png}

%% \centering  McCarthy 1959 Lisp  $\longrightarrow$ Modern functional programming
  
%%   22 tasks. 64 CPUs. 93 hours.

%%   \end{frame}

%% \begin{frame}{Symbolic regression from visual input}
%% \centering\includegraphics[width = 5cm]{symbolicRegression.png}
%% \end{frame}

\begin{frame}{DreamCoder Domains}
  \only<1>{\includegraphics[width = \textwidth]{statement/taskbar2.png}}
  \only<2>{\includegraphics[width = \textwidth]{statement/taskbar3.png}}
\end{frame}

\begin{frame}{LOGO Graphics}
  30 out of 160 tasks
  \includegraphics[width = \textwidth]{dc/logoTasks30.png}
\end{frame}

\begin{frame}{LOGO Graphics -- learning interpretable library of concepts}
  \Wider[5em]{
    \includegraphics[width = \textwidth]{dc/logo_kathy.png}
  }

  \only<2>{
  \messageOverlay{
    \begin{tabular}{rl}
    circle$(r)$
    &\raisebox{-.5\height}{\includegraphics[width = 0.3\textwidth]{dc/logo_primitives/circle_negative.png}}\\
    polygon$(n,\ell)$
    &\raisebox{-.5\height}{\includegraphics[width = 0.3\textwidth]{dc/logo_primitives/polygon_negative.png}}
  \end{tabular}
  }}
  \only<3>{
    \messageOverlay{\begin{tabular}{c}
    radial symmetry$(n,\text{body})$\\
    \includegraphics[width = 0.35\textwidth]{dc/rotationalmontage_negative.png}
  \end{tabular}}
    }
\end{frame}

\begin{frame}{what does DreamCoder dream of?}
  \Wider[5em]{
    \only<1>{\begin{tabular}{lll}
    before learning&&after learning\\
    \includegraphics[height=3cm]{dc/dreams/beforeLearning25September11}&&
    \includegraphics[height=3cm]{dc/dreams/cherry_picked/montageSeptember14}    
    \end{tabular}}
    \only<2>{\begin{tabular}{lll}
        before learning&&after learning\\
        \includegraphics[width = 0.4\textwidth]{dc/dreams/appendixlogoinitial.png}&&
        \includegraphics[width = 0.4\textwidth]{dc/dreams/appendixlogofinal.png}
        \end{tabular}}
    }

\end{frame}

\begin{frame}{Planning to build towers}
  \Wider[5.5em]{
    \footnotesize
    \begin{tabular}{l}
      {example tasks (112 total)}\\
      \includegraphics[clip, trim = 0 0cm 0 2.9cm,width = 0.9\textwidth]{dc/tower_montage_21_negative.png}\\\\

    \end{tabular}
    \pause
    \begin{tabular}{l}
      {learned library routines ($\approx $ 20 total)}\\
      \begin{tabular}[t]{rlrl}
        arch$(h)$&%\begin{tabular}{l}
        \raisebox{-.1\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_towerArch.png}}&
        %\end{tabular}&
        pyramid$(h)$&
        \raisebox{-.1\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_pyramid.png}}
        \\
        wall$(w,h)$&
        \raisebox{-.3\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_bricks.png}}
        &%\\\\
        %% stairs$(h)$&\begin{tabular}{l}
        %%   \includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_staircase.png}
        %% \end{tabular}\\\\
        \phantom{bbb}bridge$(w,h)$&
        \raisebox{-.3\height}{\includegraphics[width = 0.25\textwidth]{dc/tower/tower_dsl_bridge.png}}
        %\\\\\\
      \end{tabular}\\\\

  \end{tabular}}

  \pause

  \messageOverlay{
    \begin{tabular}{ll}
          \textbf{dreams before learning}&\textbf{dreams after learning}\\
          \begin{tabular}{c}
            \includegraphics[clip,trim = 0 4.5cm 0 0cm,width = 0.4\textwidth]{dc/tower/dreams/cherry_montage_initial_20.png}
          \end{tabular}\phantom{testing}&
          \begin{tabular}{c}
            \includegraphics[clip,trim = 0 4.5cm 0 0cm,width = 0.4\textwidth]{dc/tower/dreams/cherry_montage_final.png}
            \end{tabular}
          \\\\
      \end{tabular}
  }
  
\end{frame}

\begin{frame}{synergy between dreaming and library learning}
    \begin{tabular}{ll}
      %    \textbf{A}\\
      \only<1>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/text_hits_average_pretty_small_yl_stage1.png}}
      \only<2>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/text_hits_average_pretty_small_yl_stage2.png}}
      \only<3>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/text_hits_average_pretty_small_yl_stage3.png}}
      \only<4->{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/text_hits_average_pretty_small_yl.png}}
      &
      \phantom{ttt}%
      \only<1>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/logo_hits_average_pretty_small_stage1.png}}
      \only<2>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/logo_hits_average_pretty_small_stage2.png}}
      \only<3>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/logo_hits_average_pretty_small_stage3.png}}
      \only<4->{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/logo_hits_average_pretty_small.png}}\\
      \only<1>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/list_hard_hits_average_pretty_small_yl_stage1.png}}
      \only<2>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/list_hard_hits_average_pretty_small_yl_stage2.png}}
      \only<3>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/list_hard_hits_average_pretty_small_yl_stage3.png}}
      \only<4->{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/list_hard_hits_average_pretty_small_yl.png}}&
      \phantom{ttt}%
      \only<1>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/rational_hits_average_pretty_small_stage1.png}}
      \only<2>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/rational_hits_average_pretty_small_stage2.png}}
      \only<3>{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/rational_hits_average_pretty_small_stage3.png}}
      \only<4->{\includegraphics[height = 2cm]{../dreamcoder/figures/learningCurves/revision/rational_hits_average_pretty_small.png}}\\
      \only<1>{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/tower_hits_ws_average_pretty_small_yl_stage1.png}}
      \only<2>{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/tower_hits_ws_average_pretty_small_yl_stage2.png}}
      \only<3>{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/tower_hits_ws_average_pretty_small_yl_stage3.png}}
      \only<4->{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/tower_hits_ws_average_pretty_small_yl.png}}&
      \phantom{tt.}%
      \only<1>{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/regex_marginal_test_unigram_gen_ws_stage1.png}}
      \only<2>{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/regex_marginal_test_unigram_gen_ws_stage2.png}}
      \only<3>{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/regex_marginal_test_unigram_gen_ws_stage3.png}}
      \only<4->{\includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/regex_marginal_test_unigram_gen_ws.png}}%
%    \includegraphics[height = 2.29cm]{../dreamcoder/figures/learningCurves/revision/regex_marginal_test_unigram_gen_ws.png}%
    \phantom{tt}\includegraphics[width = 2.5cm]{../dreamcoder/figures/learningCurves/revision/curveLegend.png}\hspace{-3cm}
    %    \includegraphics[width = 0.25\textwidth]{../dreamcoder/figures/learningCurves/revision/depthVersusAccuracy_revision_MAX.png}
    \end{tabular}


      %% }
      %% }

\end{frame}

\begin{frame}{synergy between dreaming and library learning}
  \begin{tikzpicture}[scale=1.5]
    {
    \begin{scope}[shift = {(1,-1)}]
    \node[align = center](synthesis) at (6,4) {Problem-solving};
    \node[align = center](Library) at (3,1) {Library};
    \node[align = center](recognitionModel) at (9,1) {Recognition \\model};

    \draw [->,thick] (synthesis.-120) to[out = -150,in = 60] node[below,rotate = 45,align = center]{{\footnotesize Trains}\\{\footnotesize (Abstraction)}} (Library.30);
    \draw [->,thick] (synthesis.-60) to[out = -30,in = 120] node[below,rotate=-45,align = center]{{\footnotesize Trains}\\{\footnotesize (Dreaming)}} (recognitionModel.150);
    \draw [->,thick] (Library.east) to[out = -30,in = 210] node[above, align = center]{{\footnotesize Trains}\\{\footnotesize (Dreaming)}} (recognitionModel.west);

    \draw [->,thick,dashed] (Library.north) to[out = 90,in = 180] node[fill=white,inner sep=0pt,align = center]{  \footnotesize{Inductive bias}\\\footnotesize{Hypothesis space}\\\footnotesize{(Wake)}} (synthesis.west);
    \draw [->,thick,dashed] (recognitionModel.north) to[out = 90,in = 0] node[fill=white,inner sep=0pt,align = center]{{\footnotesize Makes tractable}\\{\footnotesize (Wake)}} (synthesis.east);
  \end{scope}}
    \end{tikzpicture}

\end{frame}

\begin{frame}{Evidence for dreaming bootstrapping better libraries}
    \begin{tabular}{rr}
%        \multicolumn{1}{l}{\textbf{B}}\\
    \includegraphics[height = 0.3\textwidth]{../dreamcoder/figures/learningCurves/revision/depthVersusAccuracy_revision_MEAN.png}&
    \includegraphics[height = 0.3\textwidth]{../dreamcoder/figures/learningCurves/revision/depthVersusAccuracy_revision_SIZE.png} \\\\
\multicolumn{2}{c}{    \includegraphics[height = 1cm]{../dreamcoder/figures/learningCurves/revision/scatterLegend.png}}
    \end{tabular}
    Dark$\to $Light: Early in learning$\to $Later in learning

  \end{frame}



\begin{frame}{Vision}


   \underline{More human-like machine intelligence}\\%Flexibly adapting to new problem domains:
   \begin{itemize}
   \item    Acquiring a domain-specific representation (DSL)
     \item Learning  to use that representation (recognition model)
   \end{itemize}
   DreamCoder: an algorithm for jointly realizing these goals

   



   \hspace{-1cm}\includegraphics[width = 12cm]{ecFigures/finale.png}

   \pause

   \Huge \centering \textbf{The End.}
  \end{frame}

\end{document}
